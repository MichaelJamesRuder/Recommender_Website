{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "#import pydotplus\n",
    "#import io\n",
    "\n",
    "import seaborn.apionly as sns\n",
    "sns.set_style(\"whitegrid\", {'grid.color': '0.9','grid.linestyle': u'--'})\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "%matplotlib inline\n",
    "import json\n",
    "\n",
    "from datetime import datetime \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunkload(data_json, n_size):\n",
    "    url_json = 'C:/Users/liche/Desktop/Document/Harvard Extension School/Project/dataset/%s.json' %(data_json)\n",
    "    urlw_json = 'C:/Users/Public/Documents/Harvard/Project/dataset/%s.json' %(data_json)\n",
    "    \n",
    "    df_data = pd.DataFrame()\n",
    "    \n",
    "    for chunk in pd.read_json(url_json, lines = True, chunksize = n_size):\n",
    "        df_data = df_data.append(chunk)\n",
    "        \n",
    "    return(df_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load business, review, user dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business.json loaded up\n",
      "review.json loaded up\n",
      "user.json loaded up\n"
     ]
    }
   ],
   "source": [
    "### load business.json\n",
    "df_business = chunkload( 'business', 5000 )\n",
    "print('business.json loaded up')\n",
    "\n",
    "### load checkin.json\n",
    "#df_checkin = chunkload( 'checkin', 5000 )\n",
    "#print('checkin.json loaded up')\n",
    "\n",
    "### load review.json\n",
    "df_review = chunkload( 'review', 500000)\n",
    "print('review.json loaded up')\n",
    "\n",
    "### load tip.json\n",
    "#df_tip = chunkload( 'tip', 500000)\n",
    "#print('tip.json loaded up')\n",
    "\n",
    "### load user.json\n",
    "df_user = chunkload( 'user', 500000)\n",
    "print('user.json loaded up')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge three dataset together and only select restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge business data with review data\n",
    "\n",
    "# Timer\n",
    "print('time: {}'.format(datetime.now().strftime(\"%X\")))\n",
    "bus_col_list = ['business_id','review_count', 'stars','categories','attributes','city', 'state']\n",
    "\n",
    "### Select restaurant\n",
    "df_restaurant = df_business[bus_col_list][df_business['categories'].apply(lambda x: 'Restaurants' in x)]\n",
    "\n",
    "review_list = ['review_id','user_id','stars','date','business_id']\n",
    "df_bus_rev =pd.merge(df_review[review_list],df_restaurant, on =['business_id'])\n",
    "\n",
    "df_bus_rev.columns = ['review_id', 'user_id', 'review_stars', 'date', 'business_id',\n",
    "       'review_count', 'business_stars', 'categories', 'attributes','city', 'state']\n",
    "\n",
    "#Timer\n",
    "print('time: {}'.format(datetime.now().strftime(\"%X\")))\n",
    "\n",
    "df_bus_rev.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merger user data with review data\n",
    "print('time: {}'.format(datetime.now().strftime(\"%X\")))\n",
    "\n",
    "user_col_list = ['user_id','average_stars','review_count','useful','yelping_since']\n",
    "df_bus_rev_user =pd.merge(df_bus_rev, df_user[user_col_list], on =['user_id'] )\n",
    "df_bus_rev_user.columns = ['review_id', 'user_id', 'review_stars', 'date', 'business_id',\n",
    "       'business_review_count', 'business_stars', 'categories', 'attributes','city', 'state', \n",
    "       'user_average_stars', 'user_review_count', 'useful', 'yelping_since']\n",
    "\n",
    "print('time: {}'.format(datetime.now().strftime(\"%X\")))\n",
    "\n",
    "## Drop nan\n",
    "df_bus_rev_user = df_bus_rev_user.dropna(axis=1, how='any')\n",
    "\n",
    "print('time: {}'.format(datetime.now().strftime(\"%X\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Delete unused variable to free up memory\n",
    "del df_user\n",
    "del df_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Add year column\n",
    "df_bus_rev_user['Year'] =df_bus_rev_user['date'].dt.year\n",
    "\n",
    "##### Add the years of yelping for user \n",
    "df_bus_rev_user['yelping_years'] = (2018 - pd.to_datetime(df_bus_rev_user['yelping_since']).dt.year)\n",
    "\n",
    "#### Predictors are the difference of using rating and average and the difference of business rating and average\n",
    "df_bus_rev_user['user_review_bias'] =  df_bus_rev_user['user_average_stars'] - df_bus_rev_user['user_average_stars'].mean()\n",
    "df_bus_rev_user['business_review_bias'] =  df_bus_rev_user['business_stars'] - df_bus_rev_user['business_stars'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_bus_rev_user.head();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to split into training and test sets\n",
    "def split_train_test(df):\n",
    "    np.random.seed(9001)\n",
    "    \n",
    "    msk = np.random.rand(len(df)) < 0.5\n",
    "    data_train = df[msk]\n",
    "    data_test = df[~msk]\n",
    "    return data_train, data_test\n",
    "\n",
    "df_bus_rev_user_train ,df_bus_rev_user_test = split_train_test(df_bus_rev_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Use data in Pittsburg to predict user reviews through both baseline model and KNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Train Accuracy Score 0.3423\n",
      "Baseline Model Test Accuracy Score 0.3428\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>test_star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>3.000774</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>2.860774</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2820</th>\n",
       "      <td>3.870774</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3088</th>\n",
       "      <td>4.200774</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>3.390774</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3440</th>\n",
       "      <td>2.990774</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>3.490774</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3518</th>\n",
       "      <td>3.490774</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3520</th>\n",
       "      <td>4.490774</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3632</th>\n",
       "      <td>3.990774</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction  test_star\n",
       "1473    3.000774          2\n",
       "2450    2.860774          5\n",
       "2820    3.870774          4\n",
       "3088    4.200774          4\n",
       "3199    3.390774          5\n",
       "3440    2.990774          3\n",
       "3464    3.490774          3\n",
       "3518    3.490774          4\n",
       "3520    4.490774          3\n",
       "3632    3.990774          4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def baseline_city(train, test, city):\n",
    "    train = train[train['city'] == city]\n",
    "    test = test[test['city'] == city]\n",
    "    \n",
    "    #### Intercept of Baseline Model is the average of Business Rating\n",
    "    intercept_train = train['business_stars'].mean() \n",
    "    intercept_test = test['business_stars'].mean()\n",
    "    \n",
    "    #### Baseline Model\n",
    "    y_train_predict = intercept_train + train['user_review_bias'] + train['business_review_bias']\n",
    "\n",
    "    y_test_predict = intercept_train + (test['user_average_stars'] - train['user_average_stars'].mean()) + (test['business_stars'] - intercept_train)\n",
    "\n",
    "    #### Response variable are the review stars\n",
    "    y_train = train['review_stars']\n",
    "    y_test = test['review_stars']\n",
    "\n",
    "    ##### Baseline Model\n",
    "\n",
    "    score_train = r2_score(y_true=y_train.values.ravel(), y_pred=y_train_predict)\n",
    "\n",
    "    score_test = r2_score(y_true=y_test.values.ravel(), y_pred=y_test_predict)\n",
    "    \n",
    "    print('Baseline Model Train Accuracy Score %0.6s\\nBaseline Model Test Accuracy Score %0.6s' %(score_train, score_test))\n",
    "    \n",
    "    #### Show the prediction and real test rating of baseline model\n",
    "    baseline_model = pd.DataFrame()\n",
    "\n",
    "    baseline_model['prediction'] =  y_test_predict\n",
    "    baseline_model['test_star'] =  y_test.values\n",
    "   \n",
    "    return(baseline_model)\n",
    "\n",
    "baseline_city(train = df_bus_rev_user_train, test = df_bus_rev_user_test, city = 'Pittsburgh').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Fucntion get_similiarity_coeff is to caculate the KNN distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "### Calculate distance only if the number of common users are more than 2\n",
    "\n",
    "def get_similiarity_coeff(x,y,common_users, reg):\n",
    "    if common_users == 0:\n",
    "        shrunk =0 \n",
    "    if (common_users == 1):\n",
    "        shrunk = np.nan \n",
    "    else:\n",
    "        pcoeff = pearsonr(x, y)[0]\n",
    "        shrunk = common_users*pearsonr(x, y)[0]/(common_users + reg)\n",
    "    \n",
    "    distance = (1-shrunk)/2\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function restaurant_city_percentile is to get top 10% restaurant in Pittsburg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of row in the subset of Pittsburg: 57516\n",
      "The number of restaurant in the subset of Pittsburg: 2064\n",
      "The number of row in the top 10 percentage restaurant: 27554\n",
      "The number of top 10 percentage restaurant of Pittsburg: 207\n"
     ]
    }
   ],
   "source": [
    "def restaurant_city_percentile(train_test, city, percentile):\n",
    "    city_data = train_test[train_test['city'] == city]\n",
    "    #print('The number of row in the subset of Pittsburg: %i' %(len(city_data)))\n",
    "    #print('The number of restaurant in the subset of Pittsburg: %i' %(len(city_data['business_id'].unique())))\n",
    "    city_sort = city_data.groupby('business_id', as_index = False)['business_review_count'].mean().sort_values(\n",
    "                                                                                'business_review_count', ascending = False)\n",
    "    #Get top 10 percentile restaurant based on the amount of revews\n",
    "    city_top = city_sort[city_sort['business_review_count'] >= city_sort[\n",
    "                                                               'business_review_count'].quantile(percentile)]['business_id']\n",
    "    \n",
    "    city_top_list = city_sort[city_sort['business_review_count'] >= city_sort[\n",
    "                                                               'business_review_count'].quantile(percentile)]\n",
    "    \n",
    "    city_top_data = pd.merge(city_top_list, city_data, on = ['business_id'])\n",
    "    return(city_top_data,  city_top)\n",
    "\n",
    "x,y= restaurant_city_percentile(train_test = df_bus_rev_user_train, city = 'Pittsburgh', percentile = 0.9)\n",
    "\n",
    "print('The number of row in the top 10 percentage restaurant: %i' %(len(x)))\n",
    "print('The number of top 10 percentage restaurant of Pittsburg: %i' %(len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function get_common_support is to get distance based on the number of common factor, pearson coefficient, and regulatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66755852563095064"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_common_support(bus_id1, bus_id2, df_reviewlist, reg):\n",
    "    common_users = -1\n",
    "    shrunk_coeff = -1\n",
    "    collist = ['business_id','user_id','user_average_stars','review_stars']\n",
    "    df_users_bus1 = df_reviewlist[collist].loc[df_reviewlist['business_id'] == bus_id1]\n",
    "    df_users_bus2 = df_reviewlist[collist].loc[df_reviewlist['business_id'] == bus_id2]  \n",
    "\n",
    "    df_users_bus1.columns = ['business_id','user_id','bus1_user_average_stars','review1_stars'] \n",
    "    df_users_bus2.columns = ['business_id','user_id','bus2_user_average_stars','review2_stars']\n",
    "\n",
    "    # Take out restaurant itself\n",
    "    if bus_id1 != bus_id2:\n",
    "        df_commonusers =  pd.merge(df_users_bus1,   df_users_bus2, on =['user_id'] )\n",
    "        common_users = df_commonusers['user_id'].size\n",
    "        \n",
    "     #To spead up only consider common use number larger than three\n",
    "        if common_users >= 3:\n",
    "            df_commonusers['bus1_userrating_bias']= df_commonusers['review1_stars']-  df_commonusers['bus1_user_average_stars']\n",
    "            df_commonusers['bus_2_userrating_bias']=  df_commonusers['review2_stars']-  df_commonusers['bus2_user_average_stars']\n",
    "            x =  df_commonusers['bus1_userrating_bias'].values\n",
    "            y=   df_commonusers['bus_2_userrating_bias'].values\n",
    "            distance_coeff = get_similiarity_coeff(x,y, common_users, reg)\n",
    "            \n",
    "        else: \n",
    "            distance_coeff = 1\n",
    "    if bus_id1 == bus_id2: \n",
    "        distance_coeff = 1\n",
    " \n",
    "    return distance_coeff\n",
    "\n",
    "#print('time: {}'.format(datetime.now().strftime(\"%X\")))\n",
    "x, y = restaurant_city_percentile(train_test = df_bus_rev_user_train, city = 'Pittsburgh', percentile = 0.9)\n",
    "\n",
    "get_common_support('1M6tA3TqxcpptHW0_hP9Kw', 'oS96aJIHFWcFAlGHKKXjaw', x, 10)\n",
    "#print('time: {}'.format(datetime.now().strftime(\"%X\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function knearest is to get nearest neigbour based on k (number of neribour), threshold (distance threshold), reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>neighbours</th>\n",
       "      <th>restaurant_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.245174</td>\n",
       "      <td>kwMJ4KfhEcrk9jiMe-S6wQ</td>\n",
       "      <td>1M6tA3TqxcpptHW0_hP9Kw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.269906</td>\n",
       "      <td>ejaUQ1hYo7Q7xCL1HdPINw</td>\n",
       "      <td>1M6tA3TqxcpptHW0_hP9Kw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.276999</td>\n",
       "      <td>u4sTiCzVeIHZY8OlaL346Q</td>\n",
       "      <td>1M6tA3TqxcpptHW0_hP9Kw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.282303</td>\n",
       "      <td>KTPRYqiFdLowAUEAnN7e3g</td>\n",
       "      <td>1M6tA3TqxcpptHW0_hP9Kw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>RvwZqjdkZ_pER0moPXLZAQ</td>\n",
       "      <td>1M6tA3TqxcpptHW0_hP9Kw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>4c19YWOjPmbFUK4-V2GEvg</td>\n",
       "      <td>1M6tA3TqxcpptHW0_hP9Kw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance              neighbours           restaurant_id\n",
       "0  0.245174  kwMJ4KfhEcrk9jiMe-S6wQ  1M6tA3TqxcpptHW0_hP9Kw\n",
       "1  0.269906  ejaUQ1hYo7Q7xCL1HdPINw  1M6tA3TqxcpptHW0_hP9Kw\n",
       "2  0.276999  u4sTiCzVeIHZY8OlaL346Q  1M6tA3TqxcpptHW0_hP9Kw\n",
       "3  0.282303  KTPRYqiFdLowAUEAnN7e3g  1M6tA3TqxcpptHW0_hP9Kw\n",
       "4  0.285714  RvwZqjdkZ_pER0moPXLZAQ  1M6tA3TqxcpptHW0_hP9Kw\n",
       "5  0.285714  4c19YWOjPmbFUK4-V2GEvg  1M6tA3TqxcpptHW0_hP9Kw"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def knearest(restaurant_id, set_of_restaurants, df_reviewlist, k, threshold, reg):\n",
    "    sim_dict = []\n",
    "    #### Take out the restaurant itself \n",
    "    for restaurant in set(set_of_restaurants) - set(restaurant_id): \n",
    "        coeff =get_common_support(restaurant_id, restaurant, df_reviewlist, reg)\n",
    "        \n",
    "    ### Set up a threshold to speed up\n",
    "        if coeff < threshold :\n",
    "            sim_dict.append({'restaurant_id':restaurant_id, 'neighbours':restaurant, 'distance': coeff})\n",
    "    \n",
    "    #### If no coeff less than threshold\n",
    "    if len(sim_dict) >= 1:\n",
    "        sim_pd = pd.DataFrame(sim_dict)\n",
    "        sim_pd = sim_pd.groupby('restaurant_id').apply(lambda x: x.sort_values('distance'\n",
    "                                                                               , ascending = True)).reset_index(drop=True)\n",
    "    else:\n",
    "        sim_dict = [{'restaurant_id':restaurant_id, 'neighbours':np.nan, 'distance': coeff}]\n",
    "        sim_pd = pd.DataFrame(sim_dict)\n",
    "        \n",
    "    neighbour_k = sim_pd[:k]\n",
    "    return(neighbour_k)\n",
    "\n",
    "#print('time: {}'.format(datetime.now().strftime(\"%X\")))\n",
    "\n",
    "data_by_city, bus_by_city = restaurant_city_percentile(train_test = df_bus_rev_user_train\n",
    "                                                       , city = 'Pittsburgh', percentile = 0.9)\n",
    "bus_id1 = '1M6tA3TqxcpptHW0_hP9Kw'\n",
    "temp = knearest(bus_id1, bus_by_city, data_by_city, k= 6, threshold = 0.5,  reg = 4)\n",
    "\n",
    "#print('time: {}'.format(datetime.now().strftime(\"%X\")))\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fucntion get_neighbours is to get the neighbour dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>neighbours</th>\n",
       "      <th>restaurant_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.192579</td>\n",
       "      <td>oS96aJIHFWcFAlGHKKXjaw</td>\n",
       "      <td>JLbgvGM4FXh9zNP4O5ZWjQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.293648</td>\n",
       "      <td>FgTzITgrmvrZqoHvkTSDzA</td>\n",
       "      <td>JLbgvGM4FXh9zNP4O5ZWjQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.302300</td>\n",
       "      <td>K-SsrPH0nFExdpLrTo1X1w</td>\n",
       "      <td>JLbgvGM4FXh9zNP4O5ZWjQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.288020</td>\n",
       "      <td>i39--wZD6L9hm9Lg90Uziw</td>\n",
       "      <td>u4sTiCzVeIHZY8OlaL346Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.305355</td>\n",
       "      <td>CK-Gv3vqIlWOrKP4fhT8_g</td>\n",
       "      <td>u4sTiCzVeIHZY8OlaL346Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.323429</td>\n",
       "      <td>KTPRYqiFdLowAUEAnN7e3g</td>\n",
       "      <td>u4sTiCzVeIHZY8OlaL346Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.258463</td>\n",
       "      <td>CK-Gv3vqIlWOrKP4fhT8_g</td>\n",
       "      <td>lKom12WnYEjH5FFemK3M1Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.259572</td>\n",
       "      <td>dLc1d1zwd1Teu2QED5TmlA</td>\n",
       "      <td>lKom12WnYEjH5FFemK3M1Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.303344</td>\n",
       "      <td>xcmmTXhuMx2fZF2Bt69F4w</td>\n",
       "      <td>lKom12WnYEjH5FFemK3M1Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.249109</td>\n",
       "      <td>e2ng0CQ69anIawqIKzhtlg</td>\n",
       "      <td>ejaUQ1hYo7Q7xCL1HdPINw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance              neighbours           restaurant_id\n",
       "0  0.192579  oS96aJIHFWcFAlGHKKXjaw  JLbgvGM4FXh9zNP4O5ZWjQ\n",
       "1  0.293648  FgTzITgrmvrZqoHvkTSDzA  JLbgvGM4FXh9zNP4O5ZWjQ\n",
       "2  0.302300  K-SsrPH0nFExdpLrTo1X1w  JLbgvGM4FXh9zNP4O5ZWjQ\n",
       "3  0.288020  i39--wZD6L9hm9Lg90Uziw  u4sTiCzVeIHZY8OlaL346Q\n",
       "4  0.305355  CK-Gv3vqIlWOrKP4fhT8_g  u4sTiCzVeIHZY8OlaL346Q\n",
       "5  0.323429  KTPRYqiFdLowAUEAnN7e3g  u4sTiCzVeIHZY8OlaL346Q\n",
       "6  0.258463  CK-Gv3vqIlWOrKP4fhT8_g  lKom12WnYEjH5FFemK3M1Q\n",
       "7  0.259572  dLc1d1zwd1Teu2QED5TmlA  lKom12WnYEjH5FFemK3M1Q\n",
       "8  0.303344  xcmmTXhuMx2fZF2Bt69F4w  lKom12WnYEjH5FFemK3M1Q\n",
       "9  0.249109  e2ng0CQ69anIawqIKzhtlg  ejaUQ1hYo7Q7xCL1HdPINw"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Pittsburg has ~2000 restaurants\n",
    "#### n is the restruant_id\n",
    "#### m is the size of set_of_restaurant we want to use out of Pittsburg ~2000 restaurant\n",
    "\n",
    "def get_neighbours(n, m, train_test, city, percentile, k, threshold, reg):\n",
    "    neighbours = pd.DataFrame()\n",
    "    data_city, bus_city_data = restaurant_city_percentile(train_test = train_test\n",
    "                                                          ,city = city, percentile = percentile)  \n",
    "    \n",
    "    ### n, m is None to run through all top 10 percentile restaurant\n",
    "    if n is None and m is None:\n",
    "        ### time print\n",
    "        i = 1 \n",
    "        for restaurants_id in bus_by_city:\n",
    "            ### time print at first i =1 and divisiable by 10\n",
    "           #if i == 1 or i % 20 ==0:\n",
    "           #     print('iteration {}: {}'.format(i, datetime.now().strftime(\"%X\")))\n",
    "                \n",
    "            set_of_restaurants = bus_city_data\n",
    "\n",
    "            neighbours = pd.concat([neighbours, knearest(restaurants_id \n",
    "                                                         ,set_of_restaurants, data_city, k= k, threshold = threshold,  reg = reg)])\n",
    "            \n",
    "            neighbours = neighbours.reset_index(drop = True)\n",
    "            i = i +1\n",
    "    ### Else can specify the number of restaurants to run through\n",
    "    else:\n",
    "        ### time print\n",
    "        i = 1\n",
    "        for restaurants_id in bus_by_city[:n]:\n",
    "            ### time print at first i =1 and divisiable by 10\n",
    "            #if i == 1 or i % 20 ==0:\n",
    "            #    print('iteration {}: {}'.format(i, datetime.now().strftime(\"%X\")))\n",
    "                \n",
    "            set_of_restaurants = bus_city_data[:m]\n",
    "            \n",
    "            ### dataframe of neighbours\n",
    "            neighbours = pd.concat([neighbours, knearest(restaurants_id \n",
    "                                                         ,set_of_restaurants, data_city, k= k, threshold = threshold,  reg = reg)])\n",
    "            neighbours = neighbours.reset_index(drop = True)\n",
    "            i = i +1\n",
    "            \n",
    "    return(neighbours)\n",
    "\n",
    "neighbours_test = get_neighbours(n = 50, m = 50, train_test = df_bus_rev_user_test\n",
    "                                 , city = 'Pittsburgh', percentile = 0.9\n",
    "                                 , k =3, threshold = 0.5, reg = 4)\n",
    "\n",
    "neighbours_train = get_neighbours(n = 50, m = 50, train_test = df_bus_rev_user_train\n",
    "                                 , city = 'Pittsburgh', percentile = 0.9\n",
    "                                 , k =3, threshold = 0.5, reg = 4)\n",
    "\n",
    "neighbours_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function merger_neighbours is to merge top 10 percentile restaurant with the rest of restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_review_bias</th>\n",
       "      <th>business_review_bias</th>\n",
       "      <th>business_stars</th>\n",
       "      <th>restaurant_id</th>\n",
       "      <th>distance</th>\n",
       "      <th>neighbour_stars</th>\n",
       "      <th>business_stars_average</th>\n",
       "      <th>business_average_neighbour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u7CxxEzx8hvjoJ8onN4zTg</td>\n",
       "      <td>faaOI6hU64h6SSaF0f11eg</td>\n",
       "      <td>-0.476715</td>\n",
       "      <td>-0.205125</td>\n",
       "      <td>3.5</td>\n",
       "      <td>u7CxxEzx8hvjoJ8onN4zTg</td>\n",
       "      <td>0.275478</td>\n",
       "      <td>4.308271</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>4.308271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mt9mrG8wALTzD3YYGim3mQ</td>\n",
       "      <td>yt3Z_CVnx6-0vwyd-46LSA</td>\n",
       "      <td>-0.616715</td>\n",
       "      <td>-0.205125</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>3.721160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cbddL2q8uRA38RwycB0FJg</td>\n",
       "      <td>iIZhrDYOmcyGdiWSWAldmw</td>\n",
       "      <td>0.393285</td>\n",
       "      <td>-0.205125</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>3.721160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PdDpIGwBZoTYzOVasT-WuA</td>\n",
       "      <td>5z587IBRnjCbo51IaHNPzQ</td>\n",
       "      <td>0.223285</td>\n",
       "      <td>0.294875</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>3.721160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P1a2WApEoMb65s14RmqV2g</td>\n",
       "      <td>XeOCjJwfLlKpkSd_oYxyGQ</td>\n",
       "      <td>0.913285</td>\n",
       "      <td>-1.205125</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>3.721160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MYyJ9orpiRq0prjVq4ku7w</td>\n",
       "      <td>Xxvz5g67eaCr3emnkY5M6w</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>-0.705125</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>3.721160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>_IAxXD30S4ODGh92m8tLJw</td>\n",
       "      <td>Xxvz5g67eaCr3emnkY5M6w</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>-0.205125</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>3.721160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VkeVbH5zcm0MBKuKtytGKw</td>\n",
       "      <td>Xxvz5g67eaCr3emnkY5M6w</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>-0.205125</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>3.721160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OFdMlXxtkU_nUh8jJ4W6GA</td>\n",
       "      <td>Xxvz5g67eaCr3emnkY5M6w</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>0.794875</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>3.721160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SvCjBtbN1cKElDKPTw9dOA</td>\n",
       "      <td>Xxvz5g67eaCr3emnkY5M6w</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>0.294875</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SvCjBtbN1cKElDKPTw9dOA</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>3.846377</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>3.846377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hDD6-yk1yuuRIvfdtHsISg</td>\n",
       "      <td>Xxvz5g67eaCr3emnkY5M6w</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>-0.705125</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>3.721160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pHpOuNf02eMyhdCnvMQGhg</td>\n",
       "      <td>Xxvz5g67eaCr3emnkY5M6w</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>-1.205125</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>3.721160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lKom12WnYEjH5FFemK3M1Q</td>\n",
       "      <td>AhoxHm569hH_PRkoegDwcA</td>\n",
       "      <td>0.173285</td>\n",
       "      <td>-0.205125</td>\n",
       "      <td>3.5</td>\n",
       "      <td>lKom12WnYEjH5FFemK3M1Q</td>\n",
       "      <td>0.263627</td>\n",
       "      <td>3.857805</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>3.857805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>w_UCGMgok7N9p0XdYBx1VQ</td>\n",
       "      <td>mb_8jXannipO5T5V5kGXiQ</td>\n",
       "      <td>-0.246715</td>\n",
       "      <td>-0.205125</td>\n",
       "      <td>3.5</td>\n",
       "      <td>w_UCGMgok7N9p0XdYBx1VQ</td>\n",
       "      <td>0.293951</td>\n",
       "      <td>4.108378</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>4.108378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ejaUQ1hYo7Q7xCL1HdPINw</td>\n",
       "      <td>CxDOIDnH8gp9KXzpBHJYXw</td>\n",
       "      <td>-0.436715</td>\n",
       "      <td>-0.205125</td>\n",
       "      <td>3.5</td>\n",
       "      <td>ejaUQ1hYo7Q7xCL1HdPINw</td>\n",
       "      <td>0.261651</td>\n",
       "      <td>4.141541</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>4.141541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               business_id                 user_id  user_review_bias  \\\n",
       "0   u7CxxEzx8hvjoJ8onN4zTg  faaOI6hU64h6SSaF0f11eg         -0.476715   \n",
       "1   mt9mrG8wALTzD3YYGim3mQ  yt3Z_CVnx6-0vwyd-46LSA         -0.616715   \n",
       "2   cbddL2q8uRA38RwycB0FJg  iIZhrDYOmcyGdiWSWAldmw          0.393285   \n",
       "3   PdDpIGwBZoTYzOVasT-WuA  5z587IBRnjCbo51IaHNPzQ          0.223285   \n",
       "4   P1a2WApEoMb65s14RmqV2g  XeOCjJwfLlKpkSd_oYxyGQ          0.913285   \n",
       "5   MYyJ9orpiRq0prjVq4ku7w  Xxvz5g67eaCr3emnkY5M6w          0.013285   \n",
       "6   _IAxXD30S4ODGh92m8tLJw  Xxvz5g67eaCr3emnkY5M6w          0.013285   \n",
       "7   VkeVbH5zcm0MBKuKtytGKw  Xxvz5g67eaCr3emnkY5M6w          0.013285   \n",
       "8   OFdMlXxtkU_nUh8jJ4W6GA  Xxvz5g67eaCr3emnkY5M6w          0.013285   \n",
       "9   SvCjBtbN1cKElDKPTw9dOA  Xxvz5g67eaCr3emnkY5M6w          0.013285   \n",
       "10  hDD6-yk1yuuRIvfdtHsISg  Xxvz5g67eaCr3emnkY5M6w          0.013285   \n",
       "11  pHpOuNf02eMyhdCnvMQGhg  Xxvz5g67eaCr3emnkY5M6w          0.013285   \n",
       "12  lKom12WnYEjH5FFemK3M1Q  AhoxHm569hH_PRkoegDwcA          0.173285   \n",
       "13  w_UCGMgok7N9p0XdYBx1VQ  mb_8jXannipO5T5V5kGXiQ         -0.246715   \n",
       "14  ejaUQ1hYo7Q7xCL1HdPINw  CxDOIDnH8gp9KXzpBHJYXw         -0.436715   \n",
       "\n",
       "    business_review_bias  business_stars           restaurant_id  distance  \\\n",
       "0              -0.205125             3.5  u7CxxEzx8hvjoJ8onN4zTg  0.275478   \n",
       "1              -0.205125             3.5                     NaN       NaN   \n",
       "2              -0.205125             3.5                     NaN       NaN   \n",
       "3               0.294875             4.0                     NaN       NaN   \n",
       "4              -1.205125             2.5                     NaN       NaN   \n",
       "5              -0.705125             3.0                     NaN       NaN   \n",
       "6              -0.205125             3.5                     NaN       NaN   \n",
       "7              -0.205125             3.5                     NaN       NaN   \n",
       "8               0.794875             4.5                     NaN       NaN   \n",
       "9               0.294875             4.0  SvCjBtbN1cKElDKPTw9dOA  0.269231   \n",
       "10             -0.705125             3.0                     NaN       NaN   \n",
       "11             -1.205125             2.5                     NaN       NaN   \n",
       "12             -0.205125             3.5  lKom12WnYEjH5FFemK3M1Q  0.263627   \n",
       "13             -0.205125             3.5  w_UCGMgok7N9p0XdYBx1VQ  0.293951   \n",
       "14             -0.205125             3.5  ejaUQ1hYo7Q7xCL1HdPINw  0.261651   \n",
       "\n",
       "    neighbour_stars  business_stars_average  business_average_neighbour  \n",
       "0          4.308271                 3.72116                    4.308271  \n",
       "1               NaN                 3.72116                    3.721160  \n",
       "2               NaN                 3.72116                    3.721160  \n",
       "3               NaN                 3.72116                    3.721160  \n",
       "4               NaN                 3.72116                    3.721160  \n",
       "5               NaN                 3.72116                    3.721160  \n",
       "6               NaN                 3.72116                    3.721160  \n",
       "7               NaN                 3.72116                    3.721160  \n",
       "8               NaN                 3.72116                    3.721160  \n",
       "9          3.846377                 3.72116                    3.846377  \n",
       "10              NaN                 3.72116                    3.721160  \n",
       "11              NaN                 3.72116                    3.721160  \n",
       "12         3.857805                 3.72116                    3.857805  \n",
       "13         4.108378                 3.72116                    4.108378  \n",
       "14         4.141541                 3.72116                    4.141541  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merger_neighbours(n, m, train_test, city, percentile, k, threshold, reg):\n",
    "       \n",
    "    data = train_test[['business_id', 'business_stars']][train_test['city'] == city]\n",
    "    neighbours = get_neighbours(n = n, m = m, train_test = train_test\n",
    "                                 , city = city, percentile = percentile\n",
    "                                 , k = k, threshold = threshold, reg = reg)\n",
    "    \n",
    "    ### Timer \n",
    "    #print('merge neighbours start: {}'.format(datetime.now().strftime(\"%X\")))\n",
    "        \n",
    "    data_neighbour = pd.merge(neighbours,  data, left_on = 'neighbours', right_on ='business_id', how = 'left' )\n",
    "\n",
    "    neighbour_average = data_neighbour.groupby('restaurant_id', as_index = False)['distance', 'business_stars'].mean()\n",
    "\n",
    "    neighbour_average = neighbour_average.rename(columns = {'restaurant_id': 'restaurant_id'\n",
    "                                                        , 'distance': 'distance'\n",
    "                                                        , 'business_stars': 'neighbour_stars'})\n",
    "    data_train = train_test[['business_id', 'user_id', 'user_review_bias', \n",
    "                                     'business_review_bias', 'business_stars']][train_test['city'] =='Pittsburgh']\n",
    "\n",
    "    data_neighbour_average = pd.merge(data_train, neighbour_average, left_on = 'business_id', \n",
    "                                 right_on = 'restaurant_id', how = 'left')\n",
    "\n",
    "    data_neighbour_average['business_stars_average'] = data_neighbour_average['business_stars'].mean()\n",
    "    \n",
    "    ### Use local neighbour average otherwise use global average if there is no neighbour\n",
    "    data_neighbour_average['business_average_neighbour'] =data_neighbour_average['neighbour_stars'].fillna(\n",
    "                                                    value= data_neighbour_average['business_stars_average'])\n",
    "\n",
    "    \n",
    "    return(data_neighbour_average)\n",
    "merger_neighbours_train = merger_neighbours(n = 50, m = 50, train_test = df_bus_rev_user_test\n",
    "                                 , city = 'Pittsburgh', percentile = 0.9\n",
    "                                 , k =3, threshold = 0.5, reg = 4)\n",
    "merger_neighbours_test = merger_neighbours(n = 50, m = 50, train_test = df_bus_rev_user_test\n",
    "                                 , city = 'Pittsburgh', percentile = 0.9\n",
    "                                 , k =3, threshold = 0.5, reg = 4)\n",
    "merger_neighbours_test.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Predictors are the difference of using rating and average and the difference of business rating and average\n",
    "df_merger_neighbours_train = merger_neighbours(neighbours_train, 'Pittsburgh', df_bus_rev_user_train)\n",
    "df_merger_neighbours_test = merger_neighbours(neighbours_test, 'Pittsburgh', df_bus_rev_user_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_prediction(n, m, train, test, city, percentile, k, threshold, reg):\n",
    "    \n",
    "    df_merger_neighbours_train = merger_neighbours(n = n, m = m, train_test = train\n",
    "                                 , city = city, percentile = percentile\n",
    "                                 , k = k, threshold = threshold, reg = reg)\n",
    "    \n",
    "    df_merger_neighbours_test = merger_neighbours(n = n, m = m, train_test = test\n",
    "                                 , city = city, percentile = percentile\n",
    "                                 , k = k, threshold = threshold, reg = reg)\n",
    "\n",
    "    ### Timer\n",
    "    #print('knn prediction start: {}'.format(datetime.now().strftime(\"%X\")))\n",
    "    \n",
    "    df_merger_neighbours_train['business_neighbour_bias'] =  df_merger_neighbours_train['business_stars'] - df_merger_neighbours_train['business_average_neighbour']\n",
    "\n",
    "    df_merger_neighbours_test['business_neighbour_bias'] =  df_merger_neighbours_test['business_stars'] - df_merger_neighbours_test['business_average_neighbour']\n",
    "\n",
    "    intercept_train = df_merger_neighbours_train['business_average_neighbour']\n",
    "    intercept_test =  df_merger_neighbours_test['business_average_neighbour']\n",
    "\n",
    "    y_train_city_predict = intercept_train + df_merger_neighbours_train['user_review_bias'] + df_merger_neighbours_train['business_neighbour_bias']\n",
    "\n",
    "    y_test_city_predict = intercept_test + df_merger_neighbours_test['user_review_bias'] + df_merger_neighbours_test['business_neighbour_bias']\n",
    "\n",
    "    #### Response variable are the review stars\n",
    "    y_train_city = train[train['city'] == 'Pittsburgh']['review_stars']\n",
    "    y_test_city = test[test['city'] == 'Pittsburgh']['review_stars']\n",
    "\n",
    "    ##### Baseline Model\n",
    "\n",
    "    score_train = r2_score(y_true=y_train_city.values.ravel(), y_pred=y_train_city_predict)\n",
    "\n",
    "    score_test = r2_score(y_true=y_test_city.values.ravel(), y_pred=y_test_city_predict)\n",
    "\n",
    "    #rint('KNN Train Accuracy Score %0.6s\\nKNN Test Accuracy Score %0.6s' %(score_train, score_test))\n",
    "    \n",
    "    return(score_test)\n",
    "    \n",
    "knn_prediction(n = None, m = None, train = df_bus_rev_user_train, test = df_bus_rev_user_test\n",
    "                                 , city = 'Pittsburgh', percentile = 0.9\n",
    "                                 , k =3, threshold = 0.5, reg = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation to get optimal K and Regulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-5bc98ff48722>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m             validation_accuracy_sqs.append(knn_prediction(n = 50, m = 50, train = train, test = val\n\u001b[0;32m     17\u001b[0m                                  \u001b[1;33m,\u001b[0m \u001b[0mcity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Pittsburgh'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpercentile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                                  , k = k , threshold = 0.5, reg =  reg))\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmax_score\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_accuracy_sqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-78-f006ab4decff>\u001b[0m in \u001b[0;36mknn_prediction\u001b[1;34m(n, m, train, test, city, percentile, k, threshold, reg)\u001b[0m\n\u001b[0;32m      3\u001b[0m     df_merger_neighbours_train = merger_neighbours(n = n, m = m, train_test = train\n\u001b[0;32m      4\u001b[0m                                  \u001b[1;33m,\u001b[0m \u001b[0mcity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpercentile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpercentile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                                  , k = k, threshold = threshold, reg = reg)\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     df_merger_neighbours_test = merger_neighbours(n = n, m = m, train_test = test\n",
      "\u001b[1;32m<ipython-input-29-a7a1ba3d6b7e>\u001b[0m in \u001b[0;36mmerger_neighbours\u001b[1;34m(n, m, train_test, city, percentile, k, threshold, reg)\u001b[0m\n\u001b[0;32m      4\u001b[0m     neighbours = get_neighbours(n = n, m = m, train_test = train_test\n\u001b[0;32m      5\u001b[0m                                  \u001b[1;33m,\u001b[0m \u001b[0mcity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpercentile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpercentile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                                  , k = k, threshold = threshold, reg = reg)\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m### Timer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-de821e631b5e>\u001b[0m in \u001b[0;36mget_neighbours\u001b[1;34m(n, m, train_test, city, percentile, k, threshold, reg)\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;31m### dataframe of neighbours\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             neighbours = pd.concat([neighbours, knearest(restaurants_id \n\u001b[1;32m---> 39\u001b[1;33m                                                          ,set_of_restaurants, data_city, k= k, threshold = threshold,  reg = reg)])\n\u001b[0m\u001b[0;32m     40\u001b[0m             \u001b[0mneighbours\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneighbours\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-7c8df2536a63>\u001b[0m in \u001b[0;36mknearest\u001b[1;34m(restaurant_id, set_of_restaurants, df_reviewlist, k, threshold, reg)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#### Take out the restaurant itself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrestaurant\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_of_restaurants\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrestaurant_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mcoeff\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mget_common_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrestaurant_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestaurant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_reviewlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m### Set up a threshold to speed up\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-ef7044e6b423>\u001b[0m in \u001b[0;36mget_common_support\u001b[1;34m(bus_id1, bus_id2, df_reviewlist, reg)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcollist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'business_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'user_average_stars'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'review_stars'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdf_users_bus1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_reviewlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcollist\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_reviewlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'business_id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mbus_id1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mdf_users_bus2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_reviewlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcollist\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_reviewlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'business_id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mbus_id2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mdf_users_bus1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'business_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'bus1_user_average_stars'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'review1_stars'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\liche\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2131\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2132\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2133\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2134\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2135\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\liche\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2176\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2177\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2178\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\liche\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_take\u001b[1;34m(self, indices, axis, convert, is_copy)\u001b[0m\n\u001b[0;32m   2148\u001b[0m         new_data = self._data.take(indices,\n\u001b[0;32m   2149\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2150\u001b[1;33m                                    verify=True)\n\u001b[0m\u001b[0;32m   2151\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\liche\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[0;32m   4257\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4258\u001b[0m         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n\u001b[1;32m-> 4259\u001b[1;33m                                     axis=axis, allow_dups=True)\n\u001b[0m\u001b[0;32m   4260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4261\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\liche\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[0;32m   4139\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4140\u001b[0m             new_blocks = self._slice_take_blocks_ax0(indexer,\n\u001b[1;32m-> 4141\u001b[1;33m                                                      fill_tuple=(fill_value,))\n\u001b[0m\u001b[0;32m   4142\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4143\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n",
      "\u001b[1;32mC:\\Users\\liche\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_tuple)\u001b[0m\n\u001b[0;32m   4219\u001b[0m                     blocks.append(blk.take_nd(blklocs[mgr_locs.indexer],\n\u001b[0;32m   4220\u001b[0m                                               \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4221\u001b[1;33m                                               fill_tuple=None))\n\u001b[0m\u001b[0;32m   4222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4223\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\liche\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m             new_values = algos.take_nd(values, indexer, axis=axis,\n\u001b[1;32m-> 1217\u001b[1;33m                                        allow_fill=False)\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\liche\\Anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[0;32m   1377\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=3)\n",
    "k_list = [3,5,7]\n",
    "reg_list = [3,5,7]\n",
    "max_score =0 \n",
    "\n",
    "# i is for the iteration of splits\n",
    "#i = 1\n",
    "\n",
    "for k in k_list:\n",
    "    for reg in reg_list:\n",
    "            #print('split = %i, k = %i, reg = %i' %(i, k, reg))\n",
    "        validation_accuracy_sqs = []\n",
    "        for train_index, val_index in kf.split(df_bus_rev_user_train):   \n",
    "            train, val = df_bus_rev_user_train.iloc[train_index], df_bus_rev_user_train.iloc[val_index]\n",
    "            \n",
    "            validation_accuracy_sqs.append(knn_prediction(n = 50, m = 50, train = train, test = val\n",
    "                                 , city = 'Pittsburgh', percentile = 0.9\n",
    "                                 , k = k , threshold = 0.5, reg =  reg))\n",
    "        \n",
    "        if max_score <= np.mean(validation_accuracy_sqs):\n",
    "            max_score = np.mean(validation_accuracy_sqs)\n",
    "            k_max = k\n",
    "            reg_max = reg\n",
    "    #i = i+1  \n",
    "\n",
    "print('Optimal accuracy score: %0.4f\\nOptimal K: %0.1f\\nOptimal Regulation: %i' \n",
    "      %(max_score, k_max, reg_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split = 1, k = 3, reg = 3\n",
      "merge neighbours start: 08:33:44\n",
      "merge neighbours start: 08:35:08\n",
      "knn prediction start: 08:35:08\n",
      "KNN Train Accuracy Score 0.3891\n",
      "KNN Test Accuracy Score 0.2316\n",
      "split = 1, k = 3, reg = 5\n",
      "merge neighbours start: 08:36:43\n",
      "merge neighbours start: 08:38:07\n",
      "knn prediction start: 08:38:07\n",
      "KNN Train Accuracy Score 0.3891\n",
      "KNN Test Accuracy Score 0.2316\n",
      "split = 1, k = 3, reg = 7\n",
      "merge neighbours start: 08:39:43\n",
      "merge neighbours start: 08:41:07\n",
      "knn prediction start: 08:41:07\n",
      "KNN Train Accuracy Score 0.3891\n",
      "KNN Test Accuracy Score 0.2316\n",
      "split = 1, k = 5, reg = 3\n",
      "merge neighbours start: 08:42:43\n",
      "merge neighbours start: 08:44:07\n",
      "knn prediction start: 08:44:07\n",
      "KNN Train Accuracy Score 0.3891\n",
      "KNN Test Accuracy Score 0.2316\n",
      "split = 1, k = 5, reg = 5\n",
      "merge neighbours start: 08:45:42\n",
      "merge neighbours start: 08:47:05\n",
      "knn prediction start: 08:47:05\n",
      "KNN Train Accuracy Score 0.3891\n",
      "KNN Test Accuracy Score 0.2316\n",
      "split = 1, k = 5, reg = 7\n",
      "merge neighbours start: 08:48:40\n",
      "merge neighbours start: 08:50:04\n",
      "knn prediction start: 08:50:04\n",
      "KNN Train Accuracy Score 0.3891\n",
      "KNN Test Accuracy Score 0.2316\n",
      "split = 1, k = 7, reg = 3\n",
      "merge neighbours start: 08:51:39\n",
      "merge neighbours start: 08:53:03\n",
      "knn prediction start: 08:53:03\n",
      "KNN Train Accuracy Score 0.3891\n",
      "KNN Test Accuracy Score 0.2316\n",
      "split = 1, k = 7, reg = 5\n",
      "merge neighbours start: 08:54:38\n",
      "merge neighbours start: 08:56:01\n",
      "knn prediction start: 08:56:01\n",
      "KNN Train Accuracy Score 0.3891\n",
      "KNN Test Accuracy Score 0.2316\n",
      "split = 1, k = 7, reg = 7\n",
      "merge neighbours start: 08:57:36\n",
      "merge neighbours start: 08:59:00\n",
      "knn prediction start: 08:59:00\n",
      "KNN Train Accuracy Score 0.3891\n",
      "KNN Test Accuracy Score 0.2316\n",
      "split = 2, k = 3, reg = 3\n",
      "merge neighbours start: 09:00:50\n",
      "merge neighbours start: 09:01:58\n",
      "knn prediction start: 09:01:59\n",
      "KNN Train Accuracy Score 0.3542\n",
      "KNN Test Accuracy Score 0.3149\n",
      "split = 2, k = 3, reg = 5\n",
      "merge neighbours start: 09:03:47\n",
      "merge neighbours start: 09:04:56\n",
      "knn prediction start: 09:04:56\n",
      "KNN Train Accuracy Score 0.3542\n",
      "KNN Test Accuracy Score 0.3149\n",
      "split = 2, k = 3, reg = 7\n",
      "merge neighbours start: 09:06:45\n",
      "merge neighbours start: 09:07:54\n",
      "knn prediction start: 09:07:54\n",
      "KNN Train Accuracy Score 0.3542\n",
      "KNN Test Accuracy Score 0.3149\n",
      "split = 2, k = 5, reg = 3\n",
      "merge neighbours start: 09:09:43\n",
      "merge neighbours start: 09:10:52\n",
      "knn prediction start: 09:10:52\n",
      "KNN Train Accuracy Score 0.3542\n",
      "KNN Test Accuracy Score 0.3149\n",
      "split = 2, k = 5, reg = 5\n",
      "merge neighbours start: 09:12:41\n",
      "merge neighbours start: 09:14:03\n",
      "knn prediction start: 09:14:03\n",
      "KNN Train Accuracy Score 0.3542\n",
      "KNN Test Accuracy Score 0.3149\n",
      "split = 2, k = 5, reg = 7\n",
      "merge neighbours start: 09:15:51\n",
      "merge neighbours start: 09:16:59\n",
      "knn prediction start: 09:16:59\n",
      "KNN Train Accuracy Score 0.3542\n",
      "KNN Test Accuracy Score 0.3149\n",
      "split = 2, k = 7, reg = 3\n",
      "merge neighbours start: 09:18:48\n",
      "merge neighbours start: 09:19:56\n",
      "knn prediction start: 09:19:56\n",
      "KNN Train Accuracy Score 0.3542\n",
      "KNN Test Accuracy Score 0.3149\n",
      "split = 2, k = 7, reg = 5\n",
      "merge neighbours start: 09:21:46\n",
      "merge neighbours start: 09:22:54\n",
      "knn prediction start: 09:22:55\n",
      "KNN Train Accuracy Score 0.3542\n",
      "KNN Test Accuracy Score 0.3149\n",
      "split = 2, k = 7, reg = 7\n",
      "merge neighbours start: 09:24:43\n",
      "merge neighbours start: 09:25:52\n",
      "knn prediction start: 09:25:52\n",
      "KNN Train Accuracy Score 0.3542\n",
      "KNN Test Accuracy Score 0.3149\n",
      "split = 3, k = 3, reg = 3\n",
      "merge neighbours start: 09:27:36\n",
      "merge neighbours start: 09:28:50\n",
      "knn prediction start: 09:28:50\n",
      "KNN Train Accuracy Score 0.2730\n",
      "KNN Test Accuracy Score 0.4409\n",
      "split = 3, k = 3, reg = 5\n",
      "merge neighbours start: 09:30:34\n",
      "merge neighbours start: 09:31:48\n",
      "knn prediction start: 09:31:48\n",
      "KNN Train Accuracy Score 0.2730\n",
      "KNN Test Accuracy Score 0.4409\n",
      "split = 3, k = 3, reg = 7\n",
      "merge neighbours start: 09:33:31\n",
      "merge neighbours start: 09:34:45\n",
      "knn prediction start: 09:34:45\n",
      "KNN Train Accuracy Score 0.2730\n",
      "KNN Test Accuracy Score 0.4409\n",
      "split = 3, k = 5, reg = 3\n",
      "merge neighbours start: 09:36:29\n",
      "merge neighbours start: 09:37:42\n",
      "knn prediction start: 09:37:42\n",
      "KNN Train Accuracy Score 0.2730\n",
      "KNN Test Accuracy Score 0.4409\n",
      "split = 3, k = 5, reg = 5\n",
      "merge neighbours start: 09:39:26\n",
      "merge neighbours start: 09:40:39\n",
      "knn prediction start: 09:40:39\n",
      "KNN Train Accuracy Score 0.2730\n",
      "KNN Test Accuracy Score 0.4409\n",
      "split = 3, k = 5, reg = 7\n",
      "merge neighbours start: 09:42:23\n",
      "merge neighbours start: 09:43:36\n",
      "knn prediction start: 09:43:36\n",
      "KNN Train Accuracy Score 0.2730\n",
      "KNN Test Accuracy Score 0.4409\n",
      "split = 3, k = 7, reg = 3\n",
      "merge neighbours start: 09:45:21\n",
      "merge neighbours start: 09:46:34\n",
      "knn prediction start: 09:46:34\n",
      "KNN Train Accuracy Score 0.2730\n",
      "KNN Test Accuracy Score 0.4409\n",
      "split = 3, k = 7, reg = 5\n",
      "merge neighbours start: 09:48:18\n",
      "merge neighbours start: 09:49:32\n",
      "knn prediction start: 09:49:32\n",
      "KNN Train Accuracy Score 0.2730\n",
      "KNN Test Accuracy Score 0.4409\n",
      "split = 3, k = 7, reg = 7\n",
      "merge neighbours start: 09:51:16\n",
      "merge neighbours start: 09:52:30\n",
      "knn prediction start: 09:52:30\n",
      "KNN Train Accuracy Score 0.2730\n",
      "KNN Test Accuracy Score 0.4409\n",
      "Optimal accuracy score: 0.4410\n",
      "Optimal drop rate: 7.0\n",
      "Optimal number of trees: 7\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=3)\n",
    "k_list = [3,5,7]\n",
    "reg_list = [3,5,7]\n",
    "max_score =0 \n",
    "\n",
    "# i is for the iteration of splits\n",
    "i = 1\n",
    "for train_index, val_index in kf.split(df_bus_rev_user_train):\n",
    "    for k in k_list:\n",
    "        for reg in reg_list:\n",
    "            print('split = %i, k = %i, reg = %i' %(i, k, reg))\n",
    "            validation_accuracy_sqs = []\n",
    "    \n",
    "            train, val = df_bus_rev_user_train.iloc[train_index], df_bus_rev_user_train.iloc[val_index]\n",
    "            \n",
    "            validation_accuracy_sqs.append(knn_prediction(n = 100, m = 100, train = train, test = val\n",
    "                                 , city = 'Pittsburgh', percentile = 0.9\n",
    "                                 , k = k , threshold = 0.5, reg =  reg))\n",
    "        \n",
    "        if max_score <= np.mean(validation_accuracy_sqs):\n",
    "            max_score = np.mean(validation_accuracy_sqs)\n",
    "            k_max = k\n",
    "            reg_max = reg\n",
    "    i = i+1  \n",
    "\n",
    "print('Optimal accuracy score: %0.4f\\nOptimal drop rate: %0.1f\\nOptimal number of trees: %i' \n",
    "      %(max_score, k_max, reg_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### User Recommender List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "def get_coeff(x,y,common_users):\n",
    "    if common_users == 0:\n",
    "        coeff =0 \n",
    "    if (common_users == 1) or (common_users == 2):\n",
    "        coeff = np.nan \n",
    "    else:\n",
    "        coeff = pearsonr(x, y)[0]\n",
    "\n",
    "    return coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.89364547003173667, 6)\n"
     ]
    }
   ],
   "source": [
    "def user_common_support(bus_id1, bus_id2, df_reviewlist):\n",
    "    common_users = -1\n",
    "    shrunk_coeff = -1\n",
    "    collist = ['business_id','user_id','user_average_stars','review_stars']\n",
    "    df_users_bus1 = df_reviewlist[collist].loc[df_reviewlist['business_id'] == bus_id1]\n",
    "    df_users_bus2 = df_reviewlist[collist].loc[df_reviewlist['business_id'] == bus_id2]  \n",
    "\n",
    "    df_users_bus1.columns = ['business_id','user_id','bus1_user_average_stars','review1_stars'] \n",
    "    df_users_bus2.columns = ['business_id','user_id','bus2_user_average_stars','review2_stars']\n",
    "\n",
    "    if bus_id1 != bus_id2:\n",
    "        df_commonusers =  pd.merge(df_users_bus1,   df_users_bus2, on =['user_id'] )\n",
    "        common_users = df_commonusers['user_id'].size\n",
    "         \n",
    "        df_commonusers['bus1_userrating_bias']= df_commonusers['review1_stars']-  df_commonusers['bus1_user_average_stars']\n",
    "        df_commonusers['bus_2_userrating_bias']=  df_commonusers['review2_stars']-  df_commonusers['bus2_user_average_stars']\n",
    "        x =  df_commonusers['bus1_userrating_bias'].values\n",
    "        y=   df_commonusers['bus_2_userrating_bias'].values\n",
    "        coeff = get_coeff(x,y, common_users)\n",
    "            \n",
    "    if bus_id1 == bus_id2: \n",
    "        coeff = 1\n",
    "        common_users = 1\n",
    "        #if common_users > 1:\n",
    "        #    print('business_id1: {}, bus1_user_bias: {}'.format(bus_id1, x))\n",
    "        #    print('business_id2: {}, bus2_user_bias: {}' .format(bus_id2, y))\n",
    "        #    print('shrunk similarities is %0.4f, common user %i\\n' %(distance_coeff, common_users))\n",
    "        \n",
    "    return (coeff, common_users)\n",
    "\n",
    "#print('time: {}'.format(datetime.now().strftime(\"%X\")))\n",
    "x, y = restaurant_city_percentile(train_test = df_bus_rev_user_train, city = 'Pittsburgh', percentile = 0.9)\n",
    "\n",
    "print(user_common_support('1M6tA3TqxcpptHW0_hP9Kw', 'oS96aJIHFWcFAlGHKKXjaw', x))\n",
    "\n",
    "#print('time: {}'.format(datetime.now().strftime(\"%X\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coeff</th>\n",
       "      <th>common_users</th>\n",
       "      <th>neighbours</th>\n",
       "      <th>restaurant_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.644264</td>\n",
       "      <td>10</td>\n",
       "      <td>ejaUQ1hYo7Q7xCL1HdPINw</td>\n",
       "      <td>1M6tA3TqxcpptHW0_hP9Kw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.134823</td>\n",
       "      <td>9</td>\n",
       "      <td>CK-Gv3vqIlWOrKP4fhT8_g</td>\n",
       "      <td>1M6tA3TqxcpptHW0_hP9Kw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.669002</td>\n",
       "      <td>8</td>\n",
       "      <td>u4sTiCzVeIHZY8OlaL346Q</td>\n",
       "      <td>1M6tA3TqxcpptHW0_hP9Kw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      coeff  common_users              neighbours           restaurant_id\n",
       "0  0.644264            10  ejaUQ1hYo7Q7xCL1HdPINw  1M6tA3TqxcpptHW0_hP9Kw\n",
       "1  0.134823             9  CK-Gv3vqIlWOrKP4fhT8_g  1M6tA3TqxcpptHW0_hP9Kw\n",
       "2  0.669002             8  u4sTiCzVeIHZY8OlaL346Q  1M6tA3TqxcpptHW0_hP9Kw"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def user_knearest(restaurant_id, set_of_restaurants, df_reviewlist, k, threshold):\n",
    "    sim_dict = []\n",
    "    #### Take out the restaurant itself but not always works\n",
    "    for restaurant in set(set_of_restaurants) - set(restaurant_id): \n",
    "        coeff, common_users =user_common_support(restaurant_id, restaurant, df_reviewlist)\n",
    "        if coeff > threshold :\n",
    "            sim_dict.append({'restaurant_id':restaurant_id, 'neighbours':restaurant\n",
    "                             , 'coeff': coeff, 'common_users':common_users})\n",
    "    \n",
    "    #### If no coeff less than threshold\n",
    "    if len(sim_dict) > 1:\n",
    "        sim_pd = pd.DataFrame(sim_dict)\n",
    "        sim_pd = sim_pd.groupby('restaurant_id').apply(lambda x: x.sort_values(['common_users','coeff']\n",
    "                                                                               , ascending = False)).reset_index(drop=True)\n",
    "    else:\n",
    "        sim_dict = [{'restaurant_id':restaurant_id, 'neighbours':np.nan, 'coeff': coeff, 'common_users':common_users}]\n",
    "        sim_pd = pd.DataFrame(sim_dict)\n",
    "        \n",
    "    neighbour_k = sim_pd[:k]\n",
    "    return(neighbour_k)\n",
    "\n",
    "#print('time: {}'.format(datetime.now().strftime(\"%X\")))\n",
    "\n",
    "data_by_city, bus_by_city = restaurant_city_percentile(train_test = df_bus_rev_user_train\n",
    "                                                       , city = 'Pittsburgh', percentile = 0.9)\n",
    "bus_id1 = '1M6tA3TqxcpptHW0_hP9Kw'\n",
    "temp = user_knearest(bus_id1, bus_by_city, data_by_city, k= 3, threshold = 0)\n",
    "\n",
    "#print('time: {}'.format(datetime.now().strftime(\"%X\")))\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_reviewd_restaurant</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>recommended_restaurant</th>\n",
       "      <th>coeff</th>\n",
       "      <th>common_users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dLc1d1zwd1Teu2QED5TmlA</td>\n",
       "      <td>5</td>\n",
       "      <td>JLbgvGM4FXh9zNP4O5ZWjQ</td>\n",
       "      <td>0.248590</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kkD0tv_e5E6a8kRpLYEcaA</td>\n",
       "      <td>5</td>\n",
       "      <td>xULATz2siGXOPia614mg2A</td>\n",
       "      <td>0.188059</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_ucDskZqK5w1QHkoA_nlRw</td>\n",
       "      <td>5</td>\n",
       "      <td>dLc1d1zwd1Teu2QED5TmlA</td>\n",
       "      <td>0.208826</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_reviewd_restaurant  review_stars  recommended_restaurant     coeff  \\\n",
       "1  dLc1d1zwd1Teu2QED5TmlA             5  JLbgvGM4FXh9zNP4O5ZWjQ  0.248590   \n",
       "2  kkD0tv_e5E6a8kRpLYEcaA             5  xULATz2siGXOPia614mg2A  0.188059   \n",
       "0  _ucDskZqK5w1QHkoA_nlRw             5  dLc1d1zwd1Teu2QED5TmlA  0.208826   \n",
       "\n",
       "   common_users  \n",
       "1            23  \n",
       "2            13  \n",
       "0             9  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def user_recommender(user_id, city, top, neighbours):\n",
    "    user_city = df_bus_rev_user_train[df_bus_rev_user_train['city'] == city]\n",
    "    user_data = user_city[['user_id', 'business_id', 'review_stars']][user_city['user_id'] == user_id]\n",
    "    user_restaurant = user_data.groupby(['user_id','business_id'], as_index = False)['review_stars'].mean()\n",
    "    \n",
    "    user_restaurant_top = user_restaurant.sort_values('review_stars', ascending = False)[['business_id', 'review_stars']][:top]\n",
    "    \n",
    "    user_restaurant.sort_values('review_stars', ascending = False)[['business_id', 'review_stars']]\n",
    "    data_by_city, bus_by_city = restaurant_city_percentile(train_test = df_bus_rev_user_train\n",
    "                                                       , city = 'Pittsburgh', percentile = 0.9)\n",
    "    neighbour = pd.DataFrame()\n",
    "    for top_restaurant in user_restaurant_top['business_id']:\n",
    "        neighbour = pd.concat([neighbour\n",
    "                              , user_knearest(top_restaurant, bus_by_city, data_by_city, k= neighbours, threshold = 0)])\n",
    "                           \n",
    "    recommender = pd.merge(user_restaurant_top, neighbour\n",
    "                           , left_on = 'business_id'\n",
    "                           , right_on = 'restaurant_id'\n",
    "                           , how = 'left')[['business_id', 'review_stars', 'coeff', 'common_users', 'neighbours']]\n",
    "    \n",
    "    recommender = recommender.sort_values(['common_users', 'coeff'], ascending = False)\n",
    "    recommender.columns = ['user_reviewd_restaurant', 'review_stars','coeff'\n",
    "                           , 'common_users','recommended_restaurant']\n",
    "\n",
    "    recommender = recommender[['user_reviewd_restaurant'\n",
    "                           ,'review_stars','recommended_restaurant'\n",
    "                           ,'coeff' , 'common_users' ]]\n",
    "\n",
    "    return(recommender)\n",
    "\n",
    "user_recommender(user_id = '3ew6BEeK14K6x6Omt5gbig', city = 'Pittsburgh'\n",
    "                , top = 3, neighbours =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['faaOI6hU64h6SSaF0f11eg', '5z587IBRnjCbo51IaHNPzQ',\n",
       "       'Xxvz5g67eaCr3emnkY5M6w', 'AhoxHm569hH_PRkoegDwcA',\n",
       "       'mb_8jXannipO5T5V5kGXiQ', 'CxDOIDnH8gp9KXzpBHJYXw',\n",
       "       '3KkT6SmPFLGvBS1pnDBr8g', 'TsBUWbhRhuiEMXb56kL0Cg',\n",
       "       'Um2iec4NKMXVpJEME3PfKg', '135DbbQnr3BEkQbBzZ9T1A',\n",
       "       '3ew6BEeK14K6x6Omt5gbig', 'g0EQGDEVFl4DMN6jfarJFg',\n",
       "       'hcZqq-a16ZTjaM2p2MljTg', 'ZLS7cwa1UplSB8nRrwrHIQ',\n",
       "       'f44In4p5PicSF4E4GaeTrw'], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bus_rev_user_train[df_bus_rev_user_train['city'] == 'Pittsburgh']['user_id'].unique()[:15]\n",
    "#print(df_bus_rev_user_train[df_bus_rev_user_train['state'] == 'PA']['city'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_city = df_bus_rev_user_train[df_bus_rev_user_train['city'] == 'Pittsburgh']\n",
    "user_data = user_city[['user_id', 'business_id', 'review_stars']][user_city['user_id'] == '3ew6BEeK14K6x6Omt5gbig']\n",
    "user_restaurant = user_data.groupby(['user_id','business_id'], as_index = False)['review_stars'].mean()\n",
    "\n",
    "user_restaurant_top = user_restaurant.sort_values('review_stars', ascending = False)[['business_id', 'review_stars']][:3]\n",
    "\n",
    "data_by_city, bus_by_city = restaurant_city_percentile(train_test = df_bus_rev_user_train\n",
    "                                                       , city = 'Pittsburgh', percentile = 0.9)\n",
    "neighbour = pd.DataFrame()\n",
    "for top_restaurant in user_restaurant_top['business_id']:\n",
    "    neighbour = pd.concat([neighbour\n",
    "                           , user_knearest(top_restaurant, bus_by_city, data_by_city, k= 1, threshold = 0)]\n",
    "                           )\n",
    "\n",
    "pd.merge(user_restaurant_top, neighbour, left_on = 'business_id', right_on = 'restaurant_id', how = 'left')\n",
    "recommender = pd.merge(user_restaurant_top, neighbour\n",
    "                           , left_on = 'business_id'\n",
    "                           , right_on = 'restaurant_id'\n",
    "                           , how = 'left')[['business_id', 'review_stars', 'coeff', 'common_users', 'neighbours']]\n",
    "    \n",
    "recommender = recommender.sort_values(['common_users', 'coeff'], ascending = False)\n",
    "recommender.columns = ['user_reviewd_restaurant', 'review_stars','coeff'\n",
    "                           , 'common_users','recommended_restaurant']\n",
    "\n",
    "recommender = recommender[['user_reviewd_restaurant'\n",
    "                           ,'review_stars','recommended_restaurant'\n",
    "                           ,'coeff' , 'common_users' ]]\n",
    "#user_restaurant.sort_values(['review_stars'], ascending = False)[:10]\n",
    "\n",
    "#user_restaurant = user_data.groupby(['user_id','business_id']).apply(lambda x: x.sort_values(['review_stars']\n",
    "# user_restaurant                                                                               , ascending = True)).reset_index(drop=True)\n",
    "\n",
    "#user_restaurant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
