{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "#import pydotplus\n",
    "#import io\n",
    "\n",
    "import seaborn.apionly as sns\n",
    "sns.set_style(\"whitegrid\", {'grid.color': '0.9','grid.linestyle': u'--'})\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "%matplotlib inline\n",
    "import json\n",
    "\n",
    "from datetime import datetime \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunkload(data_json, n_size):\n",
    "    url_json = 'C:/Users/liche/Desktop/Document/Harvard Extension School/Project/dataset/%s.json' %(data_json)\n",
    "    urlw_json = 'C:/Users/Public/Documents/Harvard/Project/dataset/%s.json' %(data_json)\n",
    "    \n",
    "    df_data = pd.DataFrame()\n",
    "    \n",
    "    for chunk in pd.read_json(urlw_json, lines = True, chunksize = n_size):\n",
    "        df_data = df_data.append(chunk)\n",
    "        \n",
    "    return(df_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load business, review, user dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business.json loaded up\n",
      "review.json loaded up\n",
      "user.json loaded up\n"
     ]
    }
   ],
   "source": [
    "### load business.json\n",
    "df_business = chunkload( 'business', 5000 )\n",
    "print('business.json loaded up')\n",
    "\n",
    "### load checkin.json\n",
    "#df_checkin = chunkload( 'checkin', 5000 )\n",
    "#print('checkin.json loaded up')\n",
    "\n",
    "### load review.json\n",
    "df_review = chunkload( 'review', 500000)\n",
    "print('review.json loaded up')\n",
    "\n",
    "### load tip.json\n",
    "#df_tip = chunkload( 'tip', 500000)\n",
    "#print('tip.json loaded up')\n",
    "\n",
    "### load user.json\n",
    "df_user = chunkload( 'user', 500000)\n",
    "print('user.json loaded up')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge three dataset together and only select restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Merge business data with review data\n",
    "\n",
    "# Timer\n",
    "#print('time: {}'.format(datetime.now().strftime(\"%X\")))\n",
    "bus_col_list = ['business_id','review_count', 'stars','categories','attributes','city', 'state']\n",
    "\n",
    "### Select restaurant\n",
    "df_restaurant = df_business[bus_col_list][df_business['categories'].apply(lambda x: 'Restaurants' in x)]\n",
    "\n",
    "review_list = ['review_id','user_id','stars','date','business_id']\n",
    "df_bus_rev =pd.merge(df_review[review_list],df_restaurant, on =['business_id'])\n",
    "\n",
    "df_bus_rev.columns = ['review_id', 'user_id', 'review_stars', 'date', 'business_id',\n",
    "       'review_count', 'business_stars', 'categories', 'attributes','city', 'state']\n",
    "\n",
    "#Timer\n",
    "#print('time: {}'.format(datetime.now().strftime(\"%X\")))\n",
    "\n",
    "df_bus_rev.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Merger user data with review data\n",
    "#print('time: {}'.format(datetime.now().strftime(\"%X\")))\n",
    "\n",
    "user_col_list = ['user_id','average_stars','review_count','useful','yelping_since']\n",
    "df_bus_rev_user =pd.merge(df_bus_rev, df_user[user_col_list], on =['user_id'] )\n",
    "df_bus_rev_user.columns = ['review_id', 'user_id', 'review_stars', 'date', 'business_id',\n",
    "       'business_review_count', 'business_stars', 'categories', 'attributes','city', 'state', \n",
    "       'user_average_stars', 'user_review_count', 'useful', 'yelping_since']\n",
    "\n",
    "#print('time: {}'.format(datetime.now().strftime(\"%X\")))\n",
    "\n",
    "## Drop nan\n",
    "df_bus_rev_user = df_bus_rev_user.dropna(axis=1, how='any')\n",
    "\n",
    "#print('time: {}'.format(datetime.now().strftime(\"%X\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Delete unused variable to free up memory\n",
    "del df_user\n",
    "del df_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Add year column\n",
    "df_bus_rev_user['Year'] =df_bus_rev_user['date'].dt.year\n",
    "\n",
    "##### Add the years of yelping for user \n",
    "df_bus_rev_user['yelping_years'] = (2018 - pd.to_datetime(df_bus_rev_user['yelping_since']).dt.year)\n",
    "\n",
    "#### Predictors are the difference of using rating and average and the difference of business rating and average\n",
    "df_bus_rev_user['user_review_bias'] =  df_bus_rev_user['user_average_stars'] - df_bus_rev_user['user_average_stars'].mean()\n",
    "df_bus_rev_user['business_review_bias'] =  df_bus_rev_user['business_stars'] - df_bus_rev_user['business_stars'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>date</th>\n",
       "      <th>business_id</th>\n",
       "      <th>business_review_count</th>\n",
       "      <th>business_stars</th>\n",
       "      <th>categories</th>\n",
       "      <th>attributes</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>user_average_stars</th>\n",
       "      <th>user_review_count</th>\n",
       "      <th>useful</th>\n",
       "      <th>yelping_since</th>\n",
       "      <th>Year</th>\n",
       "      <th>yelping_years</th>\n",
       "      <th>user_review_bias</th>\n",
       "      <th>business_review_bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ByRzJ8rF2KJWLr-cUNU6EA</td>\n",
       "      <td>kzyLOqiJvyw_FWFTw2rjiQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-03</td>\n",
       "      <td>jQsNFOzDpxPmOurSWCg1vQ</td>\n",
       "      <td>92</td>\n",
       "      <td>3.5</td>\n",
       "      <td>[Fast Food, Gluten-Free, Asian Fusion, Diners,...</td>\n",
       "      <td>{'RestaurantsTableService': False, 'GoodForMea...</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>AZ</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06-17</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.726715</td>\n",
       "      <td>-0.205125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YtWjIKrGGOG_bMH2I7W7HA</td>\n",
       "      <td>kzyLOqiJvyw_FWFTw2rjiQ</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-06-20</td>\n",
       "      <td>JrEMvvNR1rUVkAMvPPZYkg</td>\n",
       "      <td>264</td>\n",
       "      <td>4.5</td>\n",
       "      <td>[Barbeque, Restaurants, Desserts, Food, Sandwi...</td>\n",
       "      <td>{'RestaurantsTableService': False, 'GoodForMea...</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06-17</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.726715</td>\n",
       "      <td>0.794875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i5UwUPlQFPLcE8p2gPFwBw</td>\n",
       "      <td>WZXp9-V2dqRRJqhGgRqueA</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>jQsNFOzDpxPmOurSWCg1vQ</td>\n",
       "      <td>92</td>\n",
       "      <td>3.5</td>\n",
       "      <td>[Fast Food, Gluten-Free, Asian Fusion, Diners,...</td>\n",
       "      <td>{'RestaurantsTableService': False, 'GoodForMea...</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>AZ</td>\n",
       "      <td>3.54</td>\n",
       "      <td>327</td>\n",
       "      <td>163</td>\n",
       "      <td>2012-09-28</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.186715</td>\n",
       "      <td>-0.205125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vZVSpyWeH5kZYbPCJzBwtQ</td>\n",
       "      <td>WZXp9-V2dqRRJqhGgRqueA</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-16</td>\n",
       "      <td>xiJU_UDQM6hk9oNAYCTzRQ</td>\n",
       "      <td>40</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[Hot Dogs, Restaurants]</td>\n",
       "      <td>{'RestaurantsTableService': False, 'GoodForMea...</td>\n",
       "      <td>Amherst</td>\n",
       "      <td>OH</td>\n",
       "      <td>3.54</td>\n",
       "      <td>327</td>\n",
       "      <td>163</td>\n",
       "      <td>2012-09-28</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.186715</td>\n",
       "      <td>0.294875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zx5NfFOpiFqbAHw0KaEwJw</td>\n",
       "      <td>WZXp9-V2dqRRJqhGgRqueA</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-15</td>\n",
       "      <td>T4hTzbaZg1m178ziHWqIqg</td>\n",
       "      <td>10</td>\n",
       "      <td>4.5</td>\n",
       "      <td>[Fast Food, Event Planning &amp; Services, Caterer...</td>\n",
       "      <td>{'RestaurantsTableService': False, 'GoodForMea...</td>\n",
       "      <td>Mentor</td>\n",
       "      <td>OH</td>\n",
       "      <td>3.54</td>\n",
       "      <td>327</td>\n",
       "      <td>163</td>\n",
       "      <td>2012-09-28</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.186715</td>\n",
       "      <td>0.794875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id  review_stars       date  \\\n",
       "0  ByRzJ8rF2KJWLr-cUNU6EA  kzyLOqiJvyw_FWFTw2rjiQ             1 2017-06-03   \n",
       "1  YtWjIKrGGOG_bMH2I7W7HA  kzyLOqiJvyw_FWFTw2rjiQ             5 2016-06-20   \n",
       "2  i5UwUPlQFPLcE8p2gPFwBw  WZXp9-V2dqRRJqhGgRqueA             4 2015-03-26   \n",
       "3  vZVSpyWeH5kZYbPCJzBwtQ  WZXp9-V2dqRRJqhGgRqueA             4 2015-09-16   \n",
       "4  Zx5NfFOpiFqbAHw0KaEwJw  WZXp9-V2dqRRJqhGgRqueA             4 2015-09-15   \n",
       "\n",
       "              business_id  business_review_count  business_stars  \\\n",
       "0  jQsNFOzDpxPmOurSWCg1vQ                     92             3.5   \n",
       "1  JrEMvvNR1rUVkAMvPPZYkg                    264             4.5   \n",
       "2  jQsNFOzDpxPmOurSWCg1vQ                     92             3.5   \n",
       "3  xiJU_UDQM6hk9oNAYCTzRQ                     40             4.0   \n",
       "4  T4hTzbaZg1m178ziHWqIqg                     10             4.5   \n",
       "\n",
       "                                          categories  \\\n",
       "0  [Fast Food, Gluten-Free, Asian Fusion, Diners,...   \n",
       "1  [Barbeque, Restaurants, Desserts, Food, Sandwi...   \n",
       "2  [Fast Food, Gluten-Free, Asian Fusion, Diners,...   \n",
       "3                            [Hot Dogs, Restaurants]   \n",
       "4  [Fast Food, Event Planning & Services, Caterer...   \n",
       "\n",
       "                                          attributes      city state  \\\n",
       "0  {'RestaurantsTableService': False, 'GoodForMea...  Surprise    AZ   \n",
       "1  {'RestaurantsTableService': False, 'GoodForMea...   Phoenix    AZ   \n",
       "2  {'RestaurantsTableService': False, 'GoodForMea...  Surprise    AZ   \n",
       "3  {'RestaurantsTableService': False, 'GoodForMea...   Amherst    OH   \n",
       "4  {'RestaurantsTableService': False, 'GoodForMea...    Mentor    OH   \n",
       "\n",
       "   user_average_stars  user_review_count  useful yelping_since  Year  \\\n",
       "0                3.00                  2       0    2016-06-17  2017   \n",
       "1                3.00                  2       0    2016-06-17  2016   \n",
       "2                3.54                327     163    2012-09-28  2015   \n",
       "3                3.54                327     163    2012-09-28  2015   \n",
       "4                3.54                327     163    2012-09-28  2015   \n",
       "\n",
       "   yelping_years  user_review_bias  business_review_bias  \n",
       "0              2         -0.726715             -0.205125  \n",
       "1              2         -0.726715              0.794875  \n",
       "2              6         -0.186715             -0.205125  \n",
       "3              6         -0.186715              0.294875  \n",
       "4              6         -0.186715              0.794875  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bus_rev_user.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to split into training and test sets\n",
    "def split_train_test(df):\n",
    "    np.random.seed(9001)\n",
    "    \n",
    "    msk = np.random.rand(len(df)) < 0.5\n",
    "    data_train = df[msk]\n",
    "    data_test = df[~msk]\n",
    "    return data_train, data_test\n",
    "\n",
    "df_bus_rev_user_train ,df_bus_rev_user_test = split_train_test(df_bus_rev_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Use data in Pittsburg to predict user reviews through both baseline model and KNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Train Accuracy Score 0.3423\n",
      "Baseline Model Test Accuracy Score 0.3428\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>test_star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>3.000774</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>2.860774</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2820</th>\n",
       "      <td>3.870774</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3088</th>\n",
       "      <td>4.200774</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>3.390774</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3440</th>\n",
       "      <td>2.990774</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>3.490774</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3518</th>\n",
       "      <td>3.490774</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3520</th>\n",
       "      <td>4.490774</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3632</th>\n",
       "      <td>3.990774</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction  test_star\n",
       "1473    3.000774          2\n",
       "2450    2.860774          5\n",
       "2820    3.870774          4\n",
       "3088    4.200774          4\n",
       "3199    3.390774          5\n",
       "3440    2.990774          3\n",
       "3464    3.490774          3\n",
       "3518    3.490774          4\n",
       "3520    4.490774          3\n",
       "3632    3.990774          4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def baseline_city(train, test, city):\n",
    "    train = train[train['city'] == city]\n",
    "    test = test[test['city'] == city]\n",
    "    \n",
    "    #### Intercept of Baseline Model is the average of Business Rating\n",
    "    intercept_train = train['business_stars'].mean() \n",
    "    intercept_test = test['business_stars'].mean()\n",
    "    \n",
    "    #### Baseline Model\n",
    "    y_train_predict = intercept_train + train['user_review_bias'] + train['business_review_bias']\n",
    "\n",
    "    y_test_predict = intercept_train + (test['user_average_stars'] - train['user_average_stars'].mean()) + (test['business_stars'] - intercept_train)\n",
    "\n",
    "    #### Response variable are the review stars\n",
    "    y_train = train['review_stars']\n",
    "    y_test = test['review_stars']\n",
    "\n",
    "    ##### Baseline Model\n",
    "\n",
    "    score_train = r2_score(y_true=y_train.values.ravel(), y_pred=y_train_predict)\n",
    "\n",
    "    score_test = r2_score(y_true=y_test.values.ravel(), y_pred=y_test_predict)\n",
    "    \n",
    "    print('Baseline Model Train Accuracy Score %0.6s\\nBaseline Model Test Accuracy Score %0.6s' %(score_train, score_test))\n",
    "    \n",
    "    #### Show the prediction and real test rating of baseline model\n",
    "    baseline_model = pd.DataFrame()\n",
    "\n",
    "    baseline_model['prediction'] =  y_test_predict\n",
    "    baseline_model['test_star'] =  y_test.values\n",
    "   \n",
    "    return(baseline_model)\n",
    "\n",
    "baseline_city(train = df_bus_rev_user_train, test = df_bus_rev_user_test, city = 'Pittsburgh').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Fucntion get_similiarity_coeff is to caculate the KNN distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "### Calculate distance only if the number of common users are more than 2\n",
    "\n",
    "def get_similiarity_coeff(x,y,common_users, reg):\n",
    "    if common_users == 0:\n",
    "        shrunk =0 \n",
    "    if (common_users == 1):\n",
    "        shrunk = np.nan \n",
    "    else:\n",
    "        pcoeff = pearsonr(x, y)[0]\n",
    "        shrunk = common_users*pearsonr(x, y)[0]/(common_users + reg)\n",
    "    \n",
    "    distance = (1-shrunk)/2\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function restaurant_city_percentile is to get top 10% restaurant in Pittsburg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of row in the top 10 percentage restaurant: 27554\n",
      "The number of top 10 percentage restaurant of Pittsburg: 207\n"
     ]
    }
   ],
   "source": [
    "def restaurant_city_percentile(train_test, city, percentile):\n",
    "    city_data = train_test[train_test['city'] == city]\n",
    "    #print('The number of row in the subset of Pittsburg: %i' %(len(city_data)))\n",
    "    #print('The number of restaurant in the subset of Pittsburg: %i' %(len(city_data['business_id'].unique())))\n",
    "    city_sort = city_data.groupby('business_id', as_index = False)['business_review_count'].mean().sort_values(\n",
    "                                                                                'business_review_count', ascending = False)\n",
    "    #Get top 10 percentile restaurant based on the amount of revews\n",
    "    city_top = city_sort[city_sort['business_review_count'] >= city_sort[\n",
    "                                                               'business_review_count'].quantile(percentile)]['business_id']\n",
    "    \n",
    "    city_top_list = city_sort[city_sort['business_review_count'] >= city_sort[\n",
    "                                                               'business_review_count'].quantile(percentile)]\n",
    "    \n",
    "    city_top_data = pd.merge(city_top_list, city_data, on = ['business_id'])\n",
    "    return(city_top_data,  city_top)\n",
    "\n",
    "x,y= restaurant_city_percentile(train_test = df_bus_rev_user_train, city = 'Pittsburgh', percentile = 0.9)\n",
    "\n",
    "print('The number of row in the top 10 percentage restaurant: %i' %(len(x)))\n",
    "print('The number of top 10 percentage restaurant of Pittsburg: %i' %(len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function get_common_support is to get distance based on the number of common factor, pearson coefficient, and regulatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66755852563095064"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_common_support(bus_id1, bus_id2, df_reviewlist, reg):\n",
    "    common_users = -1\n",
    "    shrunk_coeff = -1\n",
    "    collist = ['business_id','user_id','user_average_stars','review_stars']\n",
    "    df_users_bus1 = df_reviewlist[collist].loc[df_reviewlist['business_id'] == bus_id1]\n",
    "    df_users_bus2 = df_reviewlist[collist].loc[df_reviewlist['business_id'] == bus_id2]  \n",
    "\n",
    "    df_users_bus1.columns = ['business_id','user_id','bus1_user_average_stars','review1_stars'] \n",
    "    df_users_bus2.columns = ['business_id','user_id','bus2_user_average_stars','review2_stars']\n",
    "\n",
    "    # Take out restaurant itself\n",
    "    if bus_id1 != bus_id2:\n",
    "        df_commonusers =  pd.merge(df_users_bus1,   df_users_bus2, on =['user_id'] )\n",
    "        common_users = df_commonusers['user_id'].size\n",
    "        \n",
    "     #To spead up only consider common use number larger than three\n",
    "        if common_users >= 3:\n",
    "            df_commonusers['bus1_userrating_bias']= df_commonusers['review1_stars']-  df_commonusers['bus1_user_average_stars']\n",
    "            df_commonusers['bus_2_userrating_bias']=  df_commonusers['review2_stars']-  df_commonusers['bus2_user_average_stars']\n",
    "            x =  df_commonusers['bus1_userrating_bias'].values\n",
    "            y=   df_commonusers['bus_2_userrating_bias'].values\n",
    "            distance_coeff = get_similiarity_coeff(x,y, common_users, reg)\n",
    "            \n",
    "        else: \n",
    "            distance_coeff = 1\n",
    "    if bus_id1 == bus_id2: \n",
    "        distance_coeff = 1\n",
    " \n",
    "    return distance_coeff\n",
    "\n",
    "#print('time: {}'.format(datetime.now().strftime(\"%X\")))\n",
    "x, y = restaurant_city_percentile(train_test = df_bus_rev_user_train, city = 'Pittsburgh', percentile = 0.9)\n",
    "\n",
    "get_common_support('1M6tA3TqxcpptHW0_hP9Kw', 'oS96aJIHFWcFAlGHKKXjaw', x, 10)\n",
    "#print('time: {}'.format(datetime.now().strftime(\"%X\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function knearest is to get nearest neigbour based on k (number of neribour), threshold (distance threshold), reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>neighbours</th>\n",
       "      <th>restaurant_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.245174</td>\n",
       "      <td>kwMJ4KfhEcrk9jiMe-S6wQ</td>\n",
       "      <td>1M6tA3TqxcpptHW0_hP9Kw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.269906</td>\n",
       "      <td>ejaUQ1hYo7Q7xCL1HdPINw</td>\n",
       "      <td>1M6tA3TqxcpptHW0_hP9Kw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.276999</td>\n",
       "      <td>u4sTiCzVeIHZY8OlaL346Q</td>\n",
       "      <td>1M6tA3TqxcpptHW0_hP9Kw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.282303</td>\n",
       "      <td>KTPRYqiFdLowAUEAnN7e3g</td>\n",
       "      <td>1M6tA3TqxcpptHW0_hP9Kw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>4c19YWOjPmbFUK4-V2GEvg</td>\n",
       "      <td>1M6tA3TqxcpptHW0_hP9Kw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>zMfZLd5_h5W8ZVxTNoeJyQ</td>\n",
       "      <td>1M6tA3TqxcpptHW0_hP9Kw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance              neighbours           restaurant_id\n",
       "0  0.245174  kwMJ4KfhEcrk9jiMe-S6wQ  1M6tA3TqxcpptHW0_hP9Kw\n",
       "1  0.269906  ejaUQ1hYo7Q7xCL1HdPINw  1M6tA3TqxcpptHW0_hP9Kw\n",
       "2  0.276999  u4sTiCzVeIHZY8OlaL346Q  1M6tA3TqxcpptHW0_hP9Kw\n",
       "3  0.282303  KTPRYqiFdLowAUEAnN7e3g  1M6tA3TqxcpptHW0_hP9Kw\n",
       "4  0.285714  4c19YWOjPmbFUK4-V2GEvg  1M6tA3TqxcpptHW0_hP9Kw\n",
       "5  0.285714  zMfZLd5_h5W8ZVxTNoeJyQ  1M6tA3TqxcpptHW0_hP9Kw"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def knearest(restaurant_id, set_of_restaurants, df_reviewlist, k, threshold, reg):\n",
    "    sim_dict = []\n",
    "    #### Take out the restaurant itself \n",
    "    for restaurant in set(set_of_restaurants) - set(restaurant_id): \n",
    "        coeff =get_common_support(restaurant_id, restaurant, df_reviewlist, reg)\n",
    "        \n",
    "    ### Set up a threshold to speed up\n",
    "        if coeff < threshold :\n",
    "            sim_dict.append({'restaurant_id':restaurant_id, 'neighbours':restaurant, 'distance': coeff})\n",
    "    \n",
    "    #### If no coeff less than threshold\n",
    "    if len(sim_dict) >= 1:\n",
    "        sim_pd = pd.DataFrame(sim_dict)\n",
    "        sim_pd = sim_pd.groupby('restaurant_id').apply(lambda x: x.sort_values('distance'\n",
    "                                                                               , ascending = True)).reset_index(drop=True)\n",
    "    else:\n",
    "        sim_dict = [{'restaurant_id':restaurant_id, 'neighbours':np.nan, 'distance': coeff}]\n",
    "        sim_pd = pd.DataFrame(sim_dict)\n",
    "        \n",
    "    neighbour_k = sim_pd[:k]\n",
    "    return(neighbour_k)\n",
    "\n",
    "#print('time: {}'.format(datetime.now().strftime(\"%X\")))\n",
    "\n",
    "data_by_city, bus_by_city = restaurant_city_percentile(train_test = df_bus_rev_user_train\n",
    "                                                       , city = 'Pittsburgh', percentile = 0.9)\n",
    "bus_id1 = '1M6tA3TqxcpptHW0_hP9Kw'\n",
    "temp = knearest(bus_id1, bus_by_city, data_by_city, k= 6, threshold = 0.5,  reg = 4)\n",
    "\n",
    "#print('time: {}'.format(datetime.now().strftime(\"%X\")))\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fucntion get_neighbours is to get the neighbour dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>neighbours</th>\n",
       "      <th>restaurant_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.192579</td>\n",
       "      <td>oS96aJIHFWcFAlGHKKXjaw</td>\n",
       "      <td>JLbgvGM4FXh9zNP4O5ZWjQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.293648</td>\n",
       "      <td>FgTzITgrmvrZqoHvkTSDzA</td>\n",
       "      <td>JLbgvGM4FXh9zNP4O5ZWjQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.302300</td>\n",
       "      <td>K-SsrPH0nFExdpLrTo1X1w</td>\n",
       "      <td>JLbgvGM4FXh9zNP4O5ZWjQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.288020</td>\n",
       "      <td>i39--wZD6L9hm9Lg90Uziw</td>\n",
       "      <td>u4sTiCzVeIHZY8OlaL346Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.305355</td>\n",
       "      <td>CK-Gv3vqIlWOrKP4fhT8_g</td>\n",
       "      <td>u4sTiCzVeIHZY8OlaL346Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.323429</td>\n",
       "      <td>KTPRYqiFdLowAUEAnN7e3g</td>\n",
       "      <td>u4sTiCzVeIHZY8OlaL346Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.258463</td>\n",
       "      <td>CK-Gv3vqIlWOrKP4fhT8_g</td>\n",
       "      <td>lKom12WnYEjH5FFemK3M1Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.259572</td>\n",
       "      <td>dLc1d1zwd1Teu2QED5TmlA</td>\n",
       "      <td>lKom12WnYEjH5FFemK3M1Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.303344</td>\n",
       "      <td>xcmmTXhuMx2fZF2Bt69F4w</td>\n",
       "      <td>lKom12WnYEjH5FFemK3M1Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.249109</td>\n",
       "      <td>e2ng0CQ69anIawqIKzhtlg</td>\n",
       "      <td>ejaUQ1hYo7Q7xCL1HdPINw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance              neighbours           restaurant_id\n",
       "0  0.192579  oS96aJIHFWcFAlGHKKXjaw  JLbgvGM4FXh9zNP4O5ZWjQ\n",
       "1  0.293648  FgTzITgrmvrZqoHvkTSDzA  JLbgvGM4FXh9zNP4O5ZWjQ\n",
       "2  0.302300  K-SsrPH0nFExdpLrTo1X1w  JLbgvGM4FXh9zNP4O5ZWjQ\n",
       "3  0.288020  i39--wZD6L9hm9Lg90Uziw  u4sTiCzVeIHZY8OlaL346Q\n",
       "4  0.305355  CK-Gv3vqIlWOrKP4fhT8_g  u4sTiCzVeIHZY8OlaL346Q\n",
       "5  0.323429  KTPRYqiFdLowAUEAnN7e3g  u4sTiCzVeIHZY8OlaL346Q\n",
       "6  0.258463  CK-Gv3vqIlWOrKP4fhT8_g  lKom12WnYEjH5FFemK3M1Q\n",
       "7  0.259572  dLc1d1zwd1Teu2QED5TmlA  lKom12WnYEjH5FFemK3M1Q\n",
       "8  0.303344  xcmmTXhuMx2fZF2Bt69F4w  lKom12WnYEjH5FFemK3M1Q\n",
       "9  0.249109  e2ng0CQ69anIawqIKzhtlg  ejaUQ1hYo7Q7xCL1HdPINw"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Pittsburg has ~2000 restaurants\n",
    "#### n is the restruant_id\n",
    "#### m is the size of set_of_restaurant we want to use out of Pittsburg ~2000 restaurant\n",
    "\n",
    "def get_neighbours(n, m, train_test, city, percentile, k, threshold, reg):\n",
    "    neighbours = pd.DataFrame()\n",
    "    data_city, bus_city_data = restaurant_city_percentile(train_test = train_test\n",
    "                                                          ,city = city, percentile = percentile)  \n",
    "    \n",
    "    ### n, m is None to run through all top 10 percentile restaurant\n",
    "    if n is None and m is None:\n",
    "        ### time print\n",
    "        i = 1 \n",
    "        for restaurants_id in bus_by_city:\n",
    "            ### time print at first i =1 and divisiable by 10\n",
    "           #if i == 1 or i % 20 ==0:\n",
    "           #     print('iteration {}: {}'.format(i, datetime.now().strftime(\"%X\")))\n",
    "                \n",
    "            set_of_restaurants = bus_city_data\n",
    "\n",
    "            neighbours = pd.concat([neighbours, knearest(restaurants_id \n",
    "                                                         ,set_of_restaurants, data_city, k= k, threshold = threshold,  reg = reg)])\n",
    "            \n",
    "            neighbours = neighbours.reset_index(drop = True)\n",
    "            i = i +1\n",
    "    ### Else can specify the number of restaurants to run through\n",
    "    else:\n",
    "        ### time print\n",
    "        i = 1\n",
    "        for restaurants_id in bus_by_city[:n]:\n",
    "            ### time print at first i =1 and divisiable by 10\n",
    "            #if i == 1 or i % 20 ==0:\n",
    "            #    print('iteration {}: {}'.format(i, datetime.now().strftime(\"%X\")))\n",
    "                \n",
    "            set_of_restaurants = bus_city_data[:m]\n",
    "            \n",
    "            ### dataframe of neighbours\n",
    "            neighbours = pd.concat([neighbours, knearest(restaurants_id \n",
    "                                                         ,set_of_restaurants, data_city, k= k, threshold = threshold,  reg = reg)])\n",
    "            neighbours = neighbours.reset_index(drop = True)\n",
    "            i = i +1\n",
    "            \n",
    "    return(neighbours)\n",
    "\n",
    "neighbours_test = get_neighbours(n = 50, m = 50, train_test = df_bus_rev_user_test\n",
    "                                 , city = 'Pittsburgh', percentile = 0.9\n",
    "                                 , k =3, threshold = 0.5, reg = 4)\n",
    "\n",
    "neighbours_train = get_neighbours(n = 50, m = 50, train_test = df_bus_rev_user_train\n",
    "                                 , city = 'Pittsburgh', percentile = 0.9\n",
    "                                 , k =3, threshold = 0.5, reg = 4)\n",
    "\n",
    "neighbours_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function merger_neighbours is to merge top 10 percentile restaurant with the rest of restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_review_bias</th>\n",
       "      <th>business_review_bias</th>\n",
       "      <th>business_stars</th>\n",
       "      <th>restaurant_id</th>\n",
       "      <th>distance</th>\n",
       "      <th>neighbour_stars</th>\n",
       "      <th>business_stars_average</th>\n",
       "      <th>business_average_neighbour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u7CxxEzx8hvjoJ8onN4zTg</td>\n",
       "      <td>faaOI6hU64h6SSaF0f11eg</td>\n",
       "      <td>-0.476715</td>\n",
       "      <td>-0.205125</td>\n",
       "      <td>3.5</td>\n",
       "      <td>u7CxxEzx8hvjoJ8onN4zTg</td>\n",
       "      <td>0.275478</td>\n",
       "      <td>4.308271</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>4.308271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mt9mrG8wALTzD3YYGim3mQ</td>\n",
       "      <td>yt3Z_CVnx6-0vwyd-46LSA</td>\n",
       "      <td>-0.616715</td>\n",
       "      <td>-0.205125</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>3.721160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cbddL2q8uRA38RwycB0FJg</td>\n",
       "      <td>iIZhrDYOmcyGdiWSWAldmw</td>\n",
       "      <td>0.393285</td>\n",
       "      <td>-0.205125</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>3.721160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PdDpIGwBZoTYzOVasT-WuA</td>\n",
       "      <td>5z587IBRnjCbo51IaHNPzQ</td>\n",
       "      <td>0.223285</td>\n",
       "      <td>0.294875</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>3.721160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P1a2WApEoMb65s14RmqV2g</td>\n",
       "      <td>XeOCjJwfLlKpkSd_oYxyGQ</td>\n",
       "      <td>0.913285</td>\n",
       "      <td>-1.205125</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>3.721160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MYyJ9orpiRq0prjVq4ku7w</td>\n",
       "      <td>Xxvz5g67eaCr3emnkY5M6w</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>-0.705125</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>3.721160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>_IAxXD30S4ODGh92m8tLJw</td>\n",
       "      <td>Xxvz5g67eaCr3emnkY5M6w</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>-0.205125</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>3.721160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VkeVbH5zcm0MBKuKtytGKw</td>\n",
       "      <td>Xxvz5g67eaCr3emnkY5M6w</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>-0.205125</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>3.721160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OFdMlXxtkU_nUh8jJ4W6GA</td>\n",
       "      <td>Xxvz5g67eaCr3emnkY5M6w</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>0.794875</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>3.721160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SvCjBtbN1cKElDKPTw9dOA</td>\n",
       "      <td>Xxvz5g67eaCr3emnkY5M6w</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>0.294875</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SvCjBtbN1cKElDKPTw9dOA</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>3.846377</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>3.846377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hDD6-yk1yuuRIvfdtHsISg</td>\n",
       "      <td>Xxvz5g67eaCr3emnkY5M6w</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>-0.705125</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>3.721160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pHpOuNf02eMyhdCnvMQGhg</td>\n",
       "      <td>Xxvz5g67eaCr3emnkY5M6w</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>-1.205125</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>3.721160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lKom12WnYEjH5FFemK3M1Q</td>\n",
       "      <td>AhoxHm569hH_PRkoegDwcA</td>\n",
       "      <td>0.173285</td>\n",
       "      <td>-0.205125</td>\n",
       "      <td>3.5</td>\n",
       "      <td>lKom12WnYEjH5FFemK3M1Q</td>\n",
       "      <td>0.263627</td>\n",
       "      <td>3.857805</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>3.857805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>w_UCGMgok7N9p0XdYBx1VQ</td>\n",
       "      <td>mb_8jXannipO5T5V5kGXiQ</td>\n",
       "      <td>-0.246715</td>\n",
       "      <td>-0.205125</td>\n",
       "      <td>3.5</td>\n",
       "      <td>w_UCGMgok7N9p0XdYBx1VQ</td>\n",
       "      <td>0.293951</td>\n",
       "      <td>4.108378</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>4.108378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ejaUQ1hYo7Q7xCL1HdPINw</td>\n",
       "      <td>CxDOIDnH8gp9KXzpBHJYXw</td>\n",
       "      <td>-0.436715</td>\n",
       "      <td>-0.205125</td>\n",
       "      <td>3.5</td>\n",
       "      <td>ejaUQ1hYo7Q7xCL1HdPINw</td>\n",
       "      <td>0.261651</td>\n",
       "      <td>4.141541</td>\n",
       "      <td>3.72116</td>\n",
       "      <td>4.141541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               business_id                 user_id  user_review_bias  \\\n",
       "0   u7CxxEzx8hvjoJ8onN4zTg  faaOI6hU64h6SSaF0f11eg         -0.476715   \n",
       "1   mt9mrG8wALTzD3YYGim3mQ  yt3Z_CVnx6-0vwyd-46LSA         -0.616715   \n",
       "2   cbddL2q8uRA38RwycB0FJg  iIZhrDYOmcyGdiWSWAldmw          0.393285   \n",
       "3   PdDpIGwBZoTYzOVasT-WuA  5z587IBRnjCbo51IaHNPzQ          0.223285   \n",
       "4   P1a2WApEoMb65s14RmqV2g  XeOCjJwfLlKpkSd_oYxyGQ          0.913285   \n",
       "5   MYyJ9orpiRq0prjVq4ku7w  Xxvz5g67eaCr3emnkY5M6w          0.013285   \n",
       "6   _IAxXD30S4ODGh92m8tLJw  Xxvz5g67eaCr3emnkY5M6w          0.013285   \n",
       "7   VkeVbH5zcm0MBKuKtytGKw  Xxvz5g67eaCr3emnkY5M6w          0.013285   \n",
       "8   OFdMlXxtkU_nUh8jJ4W6GA  Xxvz5g67eaCr3emnkY5M6w          0.013285   \n",
       "9   SvCjBtbN1cKElDKPTw9dOA  Xxvz5g67eaCr3emnkY5M6w          0.013285   \n",
       "10  hDD6-yk1yuuRIvfdtHsISg  Xxvz5g67eaCr3emnkY5M6w          0.013285   \n",
       "11  pHpOuNf02eMyhdCnvMQGhg  Xxvz5g67eaCr3emnkY5M6w          0.013285   \n",
       "12  lKom12WnYEjH5FFemK3M1Q  AhoxHm569hH_PRkoegDwcA          0.173285   \n",
       "13  w_UCGMgok7N9p0XdYBx1VQ  mb_8jXannipO5T5V5kGXiQ         -0.246715   \n",
       "14  ejaUQ1hYo7Q7xCL1HdPINw  CxDOIDnH8gp9KXzpBHJYXw         -0.436715   \n",
       "\n",
       "    business_review_bias  business_stars           restaurant_id  distance  \\\n",
       "0              -0.205125             3.5  u7CxxEzx8hvjoJ8onN4zTg  0.275478   \n",
       "1              -0.205125             3.5                     NaN       NaN   \n",
       "2              -0.205125             3.5                     NaN       NaN   \n",
       "3               0.294875             4.0                     NaN       NaN   \n",
       "4              -1.205125             2.5                     NaN       NaN   \n",
       "5              -0.705125             3.0                     NaN       NaN   \n",
       "6              -0.205125             3.5                     NaN       NaN   \n",
       "7              -0.205125             3.5                     NaN       NaN   \n",
       "8               0.794875             4.5                     NaN       NaN   \n",
       "9               0.294875             4.0  SvCjBtbN1cKElDKPTw9dOA  0.269231   \n",
       "10             -0.705125             3.0                     NaN       NaN   \n",
       "11             -1.205125             2.5                     NaN       NaN   \n",
       "12             -0.205125             3.5  lKom12WnYEjH5FFemK3M1Q  0.263627   \n",
       "13             -0.205125             3.5  w_UCGMgok7N9p0XdYBx1VQ  0.293951   \n",
       "14             -0.205125             3.5  ejaUQ1hYo7Q7xCL1HdPINw  0.261651   \n",
       "\n",
       "    neighbour_stars  business_stars_average  business_average_neighbour  \n",
       "0          4.308271                 3.72116                    4.308271  \n",
       "1               NaN                 3.72116                    3.721160  \n",
       "2               NaN                 3.72116                    3.721160  \n",
       "3               NaN                 3.72116                    3.721160  \n",
       "4               NaN                 3.72116                    3.721160  \n",
       "5               NaN                 3.72116                    3.721160  \n",
       "6               NaN                 3.72116                    3.721160  \n",
       "7               NaN                 3.72116                    3.721160  \n",
       "8               NaN                 3.72116                    3.721160  \n",
       "9          3.846377                 3.72116                    3.846377  \n",
       "10              NaN                 3.72116                    3.721160  \n",
       "11              NaN                 3.72116                    3.721160  \n",
       "12         3.857805                 3.72116                    3.857805  \n",
       "13         4.108378                 3.72116                    4.108378  \n",
       "14         4.141541                 3.72116                    4.141541  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merger_neighbours(n, m, train_test, city, percentile, k, threshold, reg):\n",
    "       \n",
    "    data = train_test[['business_id', 'business_stars']][train_test['city'] == city]\n",
    "    neighbours = get_neighbours(n = n, m = m, train_test = train_test\n",
    "                                 , city = city, percentile = percentile\n",
    "                                 , k = k, threshold = threshold, reg = reg)\n",
    "    \n",
    "    ### Timer \n",
    "    #print('merge neighbours start: {}'.format(datetime.now().strftime(\"%X\")))\n",
    "        \n",
    "    data_neighbour = pd.merge(neighbours,  data, left_on = 'neighbours', right_on ='business_id', how = 'left' )\n",
    "\n",
    "    neighbour_average = data_neighbour.groupby('restaurant_id', as_index = False)['distance', 'business_stars'].mean()\n",
    "\n",
    "    neighbour_average = neighbour_average.rename(columns = {'restaurant_id': 'restaurant_id'\n",
    "                                                        , 'distance': 'distance'\n",
    "                                                        , 'business_stars': 'neighbour_stars'})\n",
    "    data_train = train_test[['business_id', 'user_id', 'user_review_bias', \n",
    "                                     'business_review_bias', 'business_stars']][train_test['city'] =='Pittsburgh']\n",
    "\n",
    "    data_neighbour_average = pd.merge(data_train, neighbour_average, left_on = 'business_id', \n",
    "                                 right_on = 'restaurant_id', how = 'left')\n",
    "\n",
    "    data_neighbour_average['business_stars_average'] = data_neighbour_average['business_stars'].mean()\n",
    "    \n",
    "    ### Use local neighbour average otherwise use global average if there is no neighbour\n",
    "    data_neighbour_average['business_average_neighbour'] =data_neighbour_average['neighbour_stars'].fillna(\n",
    "                                                    value= data_neighbour_average['business_stars_average'])\n",
    "\n",
    "    \n",
    "    return(data_neighbour_average)\n",
    "merger_neighbours_train = merger_neighbours(n = 50, m = 50, train_test = df_bus_rev_user_test\n",
    "                                 , city = 'Pittsburgh', percentile = 0.9\n",
    "                                 , k =3, threshold = 0.5, reg = 4)\n",
    "merger_neighbours_test = merger_neighbours(n = 50, m = 50, train_test = df_bus_rev_user_test\n",
    "                                 , city = 'Pittsburgh', percentile = 0.9\n",
    "                                 , k =3, threshold = 0.5, reg = 4)\n",
    "merger_neighbours_test.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34267677436886135"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def knn_prediction(n, m, train, test, city, percentile, k, threshold, reg):\n",
    "    \n",
    "    df_merger_neighbours_train = merger_neighbours(n = n, m = m, train_test = train\n",
    "                                 , city = city, percentile = percentile\n",
    "                                 , k = k, threshold = threshold, reg = reg)\n",
    "    \n",
    "    df_merger_neighbours_test = merger_neighbours(n = n, m = m, train_test = test\n",
    "                                 , city = city, percentile = percentile\n",
    "                                 , k = k, threshold = threshold, reg = reg)\n",
    "\n",
    "    ### Timer\n",
    "    #print('knn prediction start: {}'.format(datetime.now().strftime(\"%X\")))\n",
    "    #intercept_train = df_merger_neighbours_train['business_average_neighbour'].mean()\n",
    "    \n",
    "    df_merger_neighbours_train['business_neighbour_bias'] =  df_merger_neighbours_train['business_stars'] - df_merger_neighbours_train['business_average_neighbour']\n",
    "    #df_merger_neighbours_train['business_neighbour_bias'] =  df_merger_neighbours_train['business_stars'] - intercept_train\n",
    "\n",
    "    df_merger_neighbours_test['business_neighbour_bias'] =  df_merger_neighbours_test['business_stars'] - df_merger_neighbours_test['business_average_neighbour']\n",
    "    #df_merger_neighbours_test['business_neighbour_bias'] =  df_merger_neighbours_test['business_stars'] - intercept_train\n",
    "    \n",
    "    intercept_train = df_merger_neighbours_train['business_average_neighbour']\n",
    "    intercept_test =  df_merger_neighbours_test['business_average_neighbour']\n",
    "\n",
    "    y_train_city_predict = intercept_train + df_merger_neighbours_train['user_review_bias'] + df_merger_neighbours_train['business_neighbour_bias']\n",
    "\n",
    "    y_test_city_predict = intercept_test + df_merger_neighbours_test['user_review_bias'] + df_merger_neighbours_test['business_neighbour_bias']\n",
    "\n",
    "    #### Response variable are the review stars\n",
    "    y_train_city = train[train['city'] == 'Pittsburgh']['review_stars']\n",
    "    y_test_city = test[test['city'] == 'Pittsburgh']['review_stars']\n",
    "\n",
    "    ##### Baseline Model\n",
    "\n",
    "    score_train = r2_score(y_true=y_train_city.values.ravel(), y_pred=y_train_city_predict)\n",
    "\n",
    "    score_test = r2_score(y_true=y_test_city.values.ravel(), y_pred=y_test_city_predict)\n",
    "\n",
    "    #rint('KNN Train Accuracy Score %0.6s\\nKNN Test Accuracy Score %0.6s' %(score_train, score_test))\n",
    "    \n",
    "    return(score_test)\n",
    "    \n",
    "knn_prediction(n = None, m = None, train = df_bus_rev_user_train, test = df_bus_rev_user_test\n",
    "                                 , city = 'Pittsburgh', percentile = 0.9\n",
    "                                 , k =7, threshold = 0.5, reg = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test R-Square is 0.34267. Through KNN model, the test r square is similar to the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation to get optimal K and Regulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal accuracy score: 0.3292\n",
      "Optimal K: 7.0\n",
      "Optimal Regulation: 7\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=3)\n",
    "k_list = [3,5,7]\n",
    "reg_list = [3,5,7]\n",
    "max_score =0 \n",
    "\n",
    "# i is for the iteration of splits\n",
    "#i = 1\n",
    "\n",
    "for k in k_list:\n",
    "    for reg in reg_list:\n",
    "            #print('split = %i, k = %i, reg = %i' %(i, k, reg))\n",
    "        validation_accuracy_sqs = []\n",
    "        for train_index, val_index in kf.split(df_bus_rev_user_train):   \n",
    "            train, val = df_bus_rev_user_train.iloc[train_index], df_bus_rev_user_train.iloc[val_index]\n",
    "            \n",
    "            validation_accuracy_sqs.append(knn_prediction(n = 100, m = 100, train = train, test = val\n",
    "                                 , city = 'Pittsburgh', percentile = 0.9\n",
    "                                 , k = k , threshold = 0.5, reg =  reg))\n",
    "        \n",
    "        if max_score <= np.mean(validation_accuracy_sqs):\n",
    "            max_score = np.mean(validation_accuracy_sqs)\n",
    "            k_max = k\n",
    "            reg_max = reg\n",
    "    #i = i+1  \n",
    "\n",
    "print('Optimal accuracy score: %0.4f\\nOptimal K: %0.1f\\nOptimal Regulation: %i' \n",
    "      %(max_score, k_max, reg_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### User Recommender List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## User List\n",
    "df_bus_rev_user_train[df_bus_rev_user_train['city'] == 'Pittsburgh']['user_id'].unique()[:15]\n",
    "#print(df_bus_rev_user_train[df_bus_rev_user_train['state'] == 'PA']['city'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "def get_coeff(x,y,common_users):\n",
    "    if common_users == 0:\n",
    "        coeff =0 \n",
    "    if (common_users == 1) or (common_users == 2):\n",
    "        coeff = np.nan \n",
    "    else:\n",
    "        coeff = pearsonr(x, y)[0]\n",
    "\n",
    "    return coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.89364547003173667, 6)\n"
     ]
    }
   ],
   "source": [
    "def user_common_support(bus_id1, bus_id2, df_reviewlist):\n",
    "    common_users = -1\n",
    "    shrunk_coeff = -1\n",
    "    collist = ['business_id','user_id','user_average_stars','review_stars']\n",
    "    df_users_bus1 = df_reviewlist[collist].loc[df_reviewlist['business_id'] == bus_id1]\n",
    "    df_users_bus2 = df_reviewlist[collist].loc[df_reviewlist['business_id'] == bus_id2]  \n",
    "\n",
    "    df_users_bus1.columns = ['business_id','user_id','bus1_user_average_stars','review1_stars'] \n",
    "    df_users_bus2.columns = ['business_id','user_id','bus2_user_average_stars','review2_stars']\n",
    "\n",
    "    if bus_id1 != bus_id2:\n",
    "        df_commonusers =  pd.merge(df_users_bus1,   df_users_bus2, on =['user_id'] )\n",
    "        common_users = df_commonusers['user_id'].size\n",
    "         \n",
    "        df_commonusers['bus1_userrating_bias']= df_commonusers['review1_stars']-  df_commonusers['bus1_user_average_stars']\n",
    "        df_commonusers['bus_2_userrating_bias']=  df_commonusers['review2_stars']-  df_commonusers['bus2_user_average_stars']\n",
    "        x =  df_commonusers['bus1_userrating_bias'].values\n",
    "        y=   df_commonusers['bus_2_userrating_bias'].values\n",
    "        coeff = get_coeff(x,y, common_users)\n",
    "            \n",
    "    if bus_id1 == bus_id2: \n",
    "        coeff = 1\n",
    "        common_users = 1\n",
    "        #if common_users > 1:\n",
    "        #    print('business_id1: {}, bus1_user_bias: {}'.format(bus_id1, x))\n",
    "        #    print('business_id2: {}, bus2_user_bias: {}' .format(bus_id2, y))\n",
    "        #    print('shrunk similarities is %0.4f, common user %i\\n' %(distance_coeff, common_users))\n",
    "        \n",
    "    return (coeff, common_users)\n",
    "\n",
    "#print('time: {}'.format(datetime.now().strftime(\"%X\")))\n",
    "x, y = restaurant_city_percentile(train_test = df_bus_rev_user_train, city = 'Pittsburgh', percentile = 0.9)\n",
    "\n",
    "print(user_common_support('1M6tA3TqxcpptHW0_hP9Kw', 'oS96aJIHFWcFAlGHKKXjaw', x))\n",
    "\n",
    "#print('time: {}'.format(datetime.now().strftime(\"%X\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coeff</th>\n",
       "      <th>common_users</th>\n",
       "      <th>neighbours</th>\n",
       "      <th>restaurant_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.644264</td>\n",
       "      <td>10</td>\n",
       "      <td>ejaUQ1hYo7Q7xCL1HdPINw</td>\n",
       "      <td>1M6tA3TqxcpptHW0_hP9Kw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.134823</td>\n",
       "      <td>9</td>\n",
       "      <td>CK-Gv3vqIlWOrKP4fhT8_g</td>\n",
       "      <td>1M6tA3TqxcpptHW0_hP9Kw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.669002</td>\n",
       "      <td>8</td>\n",
       "      <td>u4sTiCzVeIHZY8OlaL346Q</td>\n",
       "      <td>1M6tA3TqxcpptHW0_hP9Kw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      coeff  common_users              neighbours           restaurant_id\n",
       "0  0.644264            10  ejaUQ1hYo7Q7xCL1HdPINw  1M6tA3TqxcpptHW0_hP9Kw\n",
       "1  0.134823             9  CK-Gv3vqIlWOrKP4fhT8_g  1M6tA3TqxcpptHW0_hP9Kw\n",
       "2  0.669002             8  u4sTiCzVeIHZY8OlaL346Q  1M6tA3TqxcpptHW0_hP9Kw"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def user_knearest(restaurant_id, set_of_restaurants, df_reviewlist, k, threshold):\n",
    "    sim_dict = []\n",
    "    #### Take out the restaurant itself but not always works\n",
    "    for restaurant in set(set_of_restaurants) - set(restaurant_id): \n",
    "        coeff, common_users =user_common_support(restaurant_id, restaurant, df_reviewlist)\n",
    "        if coeff > threshold :\n",
    "            sim_dict.append({'restaurant_id':restaurant_id, 'neighbours':restaurant\n",
    "                             , 'coeff': coeff, 'common_users':common_users})\n",
    "    \n",
    "    #### If no coeff less than threshold\n",
    "    if len(sim_dict) > 1:\n",
    "        sim_pd = pd.DataFrame(sim_dict)\n",
    "        sim_pd = sim_pd.groupby('restaurant_id').apply(lambda x: x.sort_values(['common_users','coeff']\n",
    "                                                                               , ascending = False)).reset_index(drop=True)\n",
    "    else:\n",
    "        sim_dict = [{'restaurant_id':restaurant_id, 'neighbours':np.nan, 'coeff': coeff, 'common_users':common_users}]\n",
    "        sim_pd = pd.DataFrame(sim_dict)\n",
    "        \n",
    "    neighbour_k = sim_pd[:k]\n",
    "    return(neighbour_k)\n",
    "\n",
    "#print('time: {}'.format(datetime.now().strftime(\"%X\")))\n",
    "\n",
    "data_by_city, bus_by_city = restaurant_city_percentile(train_test = df_bus_rev_user_train\n",
    "                                                       , city = 'Pittsburgh', percentile = 0.9)\n",
    "bus_id1 = '1M6tA3TqxcpptHW0_hP9Kw'\n",
    "temp = user_knearest(bus_id1, bus_by_city, data_by_city, k= 3, threshold = 0)\n",
    "\n",
    "#print('time: {}'.format(datetime.now().strftime(\"%X\")))\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_reviewd_restaurant</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>recommended_restaurant</th>\n",
       "      <th>coeff</th>\n",
       "      <th>common_users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dLc1d1zwd1Teu2QED5TmlA</td>\n",
       "      <td>5</td>\n",
       "      <td>JLbgvGM4FXh9zNP4O5ZWjQ</td>\n",
       "      <td>0.248590</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kkD0tv_e5E6a8kRpLYEcaA</td>\n",
       "      <td>5</td>\n",
       "      <td>xULATz2siGXOPia614mg2A</td>\n",
       "      <td>0.188059</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_ucDskZqK5w1QHkoA_nlRw</td>\n",
       "      <td>5</td>\n",
       "      <td>dLc1d1zwd1Teu2QED5TmlA</td>\n",
       "      <td>0.208826</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_reviewd_restaurant  review_stars  recommended_restaurant     coeff  \\\n",
       "1  dLc1d1zwd1Teu2QED5TmlA             5  JLbgvGM4FXh9zNP4O5ZWjQ  0.248590   \n",
       "2  kkD0tv_e5E6a8kRpLYEcaA             5  xULATz2siGXOPia614mg2A  0.188059   \n",
       "0  _ucDskZqK5w1QHkoA_nlRw             5  dLc1d1zwd1Teu2QED5TmlA  0.208826   \n",
       "\n",
       "   common_users  \n",
       "1            23  \n",
       "2            13  \n",
       "0             9  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def user_recommender(user_id, city, top, neighbours):\n",
    "    user_city = df_bus_rev_user_train[df_bus_rev_user_train['city'] == city]\n",
    "    user_data = user_city[['user_id', 'business_id', 'review_stars']][user_city['user_id'] == user_id]\n",
    "    user_restaurant = user_data.groupby(['user_id','business_id'], as_index = False)['review_stars'].mean()\n",
    "    \n",
    "    user_restaurant_top = user_restaurant.sort_values('review_stars', ascending = False)[['business_id', 'review_stars']][:top]\n",
    "    \n",
    "    user_restaurant.sort_values('review_stars', ascending = False)[['business_id', 'review_stars']]\n",
    "    data_by_city, bus_by_city = restaurant_city_percentile(train_test = df_bus_rev_user_train\n",
    "                                                       , city = 'Pittsburgh', percentile = 0.9)\n",
    "    neighbour = pd.DataFrame()\n",
    "    for top_restaurant in user_restaurant_top['business_id']:\n",
    "        neighbour = pd.concat([neighbour\n",
    "                              , user_knearest(top_restaurant, bus_by_city, data_by_city, k= neighbours, threshold = 0)])\n",
    "                           \n",
    "    recommender = pd.merge(user_restaurant_top, neighbour\n",
    "                           , left_on = 'business_id'\n",
    "                           , right_on = 'restaurant_id'\n",
    "                           , how = 'left')[['business_id', 'review_stars', 'coeff', 'common_users', 'neighbours']]\n",
    "    \n",
    "    recommender = recommender.sort_values(['common_users', 'coeff'], ascending = False)\n",
    "    recommender.columns = ['user_reviewd_restaurant', 'review_stars','coeff'\n",
    "                           , 'common_users','recommended_restaurant']\n",
    "\n",
    "    recommender = recommender[['user_reviewd_restaurant'\n",
    "                           ,'review_stars','recommended_restaurant'\n",
    "                           ,'coeff' , 'common_users' ]]\n",
    "\n",
    "    return(recommender)\n",
    "\n",
    "user_recommender(user_id = '3ew6BEeK14K6x6Omt5gbig', city = 'Pittsburgh'\n",
    "                , top = 3, neighbours =1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### We also build recommender list. Given the user id, we will find the closest neighbour of the users' top reviewed restaurants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
